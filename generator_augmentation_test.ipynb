{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabv3plus_dir=\"./src\"\n",
    "sys.path.append(deeplabv3plus_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(visible_device_list=\"3\", allow_growth=True)\n",
    "config = tf.compat.v1.ConfigProto(gpu_options = gpu_options)\n",
    "tf.compat.v1.enable_eager_execution(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from model import deeplab_v3plus\n",
    "from data_utils import make_xy_from_data_paths, convert_y_to_image_array\n",
    "from data_gen import DataGenerator\n",
    "from label import Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#importlib.reload(sys.modules['DataGenerator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_dir = '../train_data'\n",
    "#testdata_dir = '../kaigan_block/dataset/x_test2'\n",
    "\n",
    "train_x_paths = glob.glob(os.path.join(traindata_dir,'*.jpg'))\n",
    "train_x_paths.sort()\n",
    "image_names = [os.path.basename(train_x_paths[i]).split('.')[0] for i in range(len(train_x_paths))]\n",
    "train_y_paths=[]\n",
    "for i, image_name in enumerate(image_names):\n",
    "    p = os.path.join(traindata_dir, image_name+'.json')\n",
    "    if os.path.exists(p):\n",
    "        train_y_paths.append(p)\n",
    "    else:\n",
    "        train_y_paths.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "seg_img_dir = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/SegmentationClass\"\n",
    "img_dir = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/JPEGImages\"\n",
    "train_set_path = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt\"\n",
    "valid_set_path = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt\"\n",
    "\n",
    "with open(train_set_path) as f:\n",
    "    train_img_names = f.read().split(\"\\n\")[:-1]\n",
    "with open(valid_set_path) as f:\n",
    "    valid_img_names = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "img_paths = [os.path.join(img_dir,train_img_names[i]) + \".jpg\" for i in range(len(train_img_names))]\n",
    "seg_img_paths = [os.path.join(seg_img_dir,train_img_names[i]) + \".png\" for i in range(len(train_img_names))]\n",
    "\n",
    "valid_x_paths = [os.path.join(img_dir,valid_img_names[i]) + \".jpg\" for i in range(len(valid_img_names))]\n",
    "valid_y_paths = [os.path.join(seg_img_dir,valid_img_names[i]) + \".png\" for i in range(len(valid_img_names))]\n",
    "#valid_x_paths = [os.path.join(img_dir,train_img_names[i]) + \".jpg\" for i in range(len(train_img_names))][0:10]\n",
    "#valid_y_paths = [os.path.join(seg_img_dir,train_img_names[i]) + \".png\" for i in range(len(train_img_names))][0:10]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file_path = os.path.join(traindata_dir, 'label_list.csv')\n",
    "label = Label(label_file_path)\n",
    "image_size = (512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "preprocess = keras.applications.xception.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = DataGenerator(train_x_paths,\n",
    "                               train_y_paths,\n",
    "                               image_size,\n",
    "                               label,\n",
    "                               batch_size,\n",
    "                               preprocess,\n",
    "                               augmentation=True,\n",
    "                               shuffle=True,\n",
    "                               resize_or_crop=\"crop\",\n",
    "                               data_type=\"polygon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y0 = train_data_gen.__getitem__(1)\n",
    "x = (x+1)/2\n",
    "y =convert_y_to_image_array(y0, image_size, label)\n",
    "\n",
    "i=3\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(x[i,:,:,:])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentor test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_xy_from_data_paths(train_x_paths[0:10],\n",
    "                               train_y_paths[0:10],\n",
    "                               image_size,\n",
    "                               label,\n",
    "                               'polygon',\n",
    "                               'crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "#aug=RandomCrop(p=1, height=300, width=300)\n",
    "#aug=ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=1)\n",
    "aug=HueSaturationValue(p=1)\n",
    "auged = aug(image=x[i,:,:,:],mask=y[i,:,:,:])\n",
    "img = auged[\"image\"]\n",
    "mask = auged[\"mask\"]\n",
    "mask = convert_y_to_image_array(mask[np.newaxis,:,:,:], image_size, label)\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(x[i,:,:,:])\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
