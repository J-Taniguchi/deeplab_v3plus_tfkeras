{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an example for the dataset which annotated as index png image like pascal voc2012.\n",
    "\n",
    "If the data are annotated as RGB image, modify data_type when you use DataGenereator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to this package's src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabv3plus_srcdir=\"./src\"\n",
    "sys.path.append(deeplabv3plus_srcdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want, write about gpu setting here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(visible_device_list=\"1\", allow_growth=True)\n",
    "config = tf.compat.v1.ConfigProto(gpu_options = gpu_options)\n",
    "tf.compat.v1.enable_eager_execution(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from image_utils import make_pascal_voc_label_csv\n",
    "#make_pascal_voc_label_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import from .src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import deeplab_v3plus_transfer_os16\n",
    "#from image_utils import make_x_from_image_paths,make_y_from_image_paths,convert_y_to_image_array\n",
    "from data_gen import DataGenerator\n",
    "from metrics import IoU\n",
    "from label import Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#importlib.reload(sys.modules['image_utils'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learned model and loss curve are exported to out_dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"TEST\"\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make train_x_paths and train_y_paths as list.\n",
    "\n",
    "The order of train_x_paths and train_y_paths mast be correspond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_img_dir = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/SegmentationClass\"\n",
    "img_dir = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/JPEGImages\"\n",
    "train_set_path = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt\"\n",
    "valid_set_path = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt\"\n",
    "\n",
    "with open(train_set_path) as f:\n",
    "    train_img_names = f.read().split(\"\\n\")[:-1]\n",
    "with open(valid_set_path) as f:\n",
    "    valid_img_names = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "train_x_paths = np.array([os.path.join(img_dir,train_img_names[i]) + \".jpg\" for i in range(len(train_img_names))])\n",
    "train_y_paths = np.array([os.path.join(seg_img_dir,train_img_names[i]) + \".png\" for i in range(len(train_img_names))])\n",
    "\n",
    "valid_x_paths = np.array([os.path.join(img_dir,valid_img_names[i]) + \".jpg\" for i in range(len(valid_img_names))])\n",
    "valid_y_paths = np.array([os.path.join(seg_img_dir,valid_img_names[i]) + \".png\" for i in range(len(valid_img_names))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set label_file_path, and image_size. Every image is resize to image_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file_path = \"./pascal_voc_label.csv\"\n",
    "label = Label(label_file_path)\n",
    "image_size = (512,512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set batch_size and n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "n_epochs=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose model from [here](https://www.tensorflow.org/api_docs/python/tf/keras/applications).\n",
    "\n",
    "If you want to do transfer learning, preprocess must be correspond to the encoder.\n",
    "\n",
    "layer_name_to_decorder means the layer name which correspond to \"Low-Level Features\" arrow in Fig.2 of the [paper](https://arxiv.org/pdf/1802.02611.pdf).\n",
    "\n",
    "encoder_end_layer_name means the layer name input to ASPP block.\n",
    "\n",
    "deeplab_v3plus_transfer_os16 makes model.\n",
    "- If you don't want to freeze encoder, write freeze_encoder=False in the function.\n",
    "- Default activation function of the last layer is softmax. If you want to use sigmoid, write output_activation='sigmoid' in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.applications.Xception(input_shape=(512,512,3), weights=\"imagenet\", include_top=False)\n",
    "preprocess = keras.applications.xception.preprocess_input\n",
    "layer_name_to_decoder = \"block3_sepconv2_bn\"\n",
    "encoder_end_layer_name = \"block13_sepconv2_bn\"\n",
    "model = deeplab_v3plus_transfer_os16(label.n_labels, encoder, layer_name_to_decoder, encoder_end_layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make data generator like this. \n",
    "\n",
    "If your dataset is annotated as RGB image, modify data_type=\"image\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = DataGenerator(train_x_paths, train_y_paths, image_size, label, batch_size, preprocess, augmentation=True, shuffle=True, data_type=\"index_png\")\n",
    "valid_data_gen = DataGenerator(valid_x_paths, valid_y_paths, image_size, label, batch_size, preprocess, augmentation=False, shuffle=False, data_type=\"index_png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model. You can change it if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.categorical_crossentropy\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=opt, loss=loss_function, metrics=[IoU])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(out_dir,'{epoch:06d}.h5')\n",
    "cp_cb = keras.callbacks.ModelCheckpoint(filepath, \n",
    "                                        monitor='val_IoU', \n",
    "                                        verbose=1, \n",
    "                                        save_best_only=True, \n",
    "                                        save_weights_only=False, \n",
    "                                        mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can modify freely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist = model.fit_generator(data_gen, validation_data=(valid_x, valid_y), epochs=par.n_epochs, steps_per_epoch=par.n_batch, callbacks=[cp_cb])\n",
    "hist = model.fit_generator(train_data_gen,\n",
    "                           epochs=n_epochs,\n",
    "                           steps_per_epoch=len(train_data_gen),\n",
    "                           validation_data=valid_data_gen,\n",
    "                           validation_steps=len(valid_data_gen),\n",
    "                           #shuffle = False,\n",
    "                           workers=8,\n",
    "                           use_multiprocessing=True,\n",
    "                           callbacks=[cp_cb])\n",
    "#hist = model.fit_generator(data_gen, epochs=par.n_epochs, steps_per_epoch=par.n_batch, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(hist.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(hist.history[\"IoU\"], label=\"IoU\")\n",
    "plt.plot(hist.history[\"val_IoU\"], label=\"val_IoU\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(out_dir,'losscurve.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save last epoch model, loss, and metrics,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(out_dir,'final_epoch.h5'))\n",
    "for key in sorted(hist.history.keys()):\n",
    "    np.savetxt(os.path.join(out_dir,key+'.txt'),np.array(hist.history[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
