{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabv3plus_srcdir=\"./src\"\n",
    "sys.path.append(deeplabv3plus_srcdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from image_utils import make_pascal_voc_label_csv\n",
    "#make_pascal_voc_label_csv()\n",
    "label_pd = pd.read_csv(\"pascal_voc_label.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(visible_device_list=\"1\", allow_growth=True)\n",
    "config = tf.compat.v1.ConfigProto(gpu_options = gpu_options)\n",
    "tf.compat.v1.enable_eager_execution(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import deeplab_v3plus_transfer_os16\n",
    "#from image_utils import make_x_from_image_paths,make_y_from_image_paths,convert_y_to_image_array\n",
    "from data_gen import DataGenerator\n",
    "from metrics import IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'image_utils' from './src/image_utils.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(sys.modules['image_utils'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"TEST\"\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories = label_pd.shape[0]\n",
    "image_size = (512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_img_dir = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/SegmentationClass\"\n",
    "img_dir = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/JPEGImages\"\n",
    "train_set_path = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt\"\n",
    "valid_set_path = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt\"\n",
    "\n",
    "with open(train_set_path) as f:\n",
    "    train_img_names = f.read().split(\"\\n\")[:-1]\n",
    "with open(valid_set_path) as f:\n",
    "    valid_img_names = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "train_x_paths = np.array([os.path.join(img_dir,train_img_names[i]) + \".jpg\" for i in range(len(train_img_names))])\n",
    "train_y_paths = np.array([os.path.join(seg_img_dir,train_img_names[i]) + \".png\" for i in range(len(train_img_names))])\n",
    "\n",
    "valid_x_paths = np.array([os.path.join(img_dir,valid_img_names[i]) + \".jpg\" for i in range(len(valid_img_names))])\n",
    "valid_y_paths = np.array([os.path.join(seg_img_dir,valid_img_names[i]) + \".png\" for i in range(len(valid_img_names))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "n_epochs=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1203 18:30:05.956824 140736324455632 module_wrapper.py:139] From ./src/model.py:207: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in decoder, layer from encoder is resized from (?, 127, 127, 256) to (?, 128, 128, 256)\n"
     ]
    }
   ],
   "source": [
    "encoder = keras.applications.Xception(input_shape=(512,512,3), weights=\"imagenet\", include_top=False)\n",
    "preprocess = keras.applications.xception.preprocess_input\n",
    "layer_name_to_decoder = \"block3_sepconv2_bn\"\n",
    "encoder_end_layer_name = \"block13_sepconv2_bn\"\n",
    "model = deeplab_v3plus_transfer_os16(n_categories, encoder, layer_name_to_decoder, encoder_end_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = DataGenerator(train_x_paths, train_y_paths, image_size, label_pd, batch_size, preprocess, augmentation=True, shuffle=True, is_index_png=True)\n",
    "valid_data_gen = DataGenerator(valid_x_paths, valid_y_paths, image_size, label_pd, batch_size, preprocess, augmentation=False, shuffle=False, is_index_png=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.categorical_crossentropy\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=opt, loss=loss_function, metrics=[IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(out_dir,'{epoch:06d}.h5')\n",
    "cp_cb = keras.callbacks.ModelCheckpoint(filepath, \n",
    "                                        monitor='val_IoU', \n",
    "                                        verbose=1, \n",
    "                                        save_best_only=True, \n",
    "                                        save_weights_only=False, \n",
    "                                        mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1203 18:30:33.629978 140736324455632 deprecation.py:323] From /home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/92 [============================>.] - ETA: 2s - loss: 2.2020 - IoU: 0.0146Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 2.4395 - IoU: 0.0000e+00Epoch 1/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 2.4404 - IoU: 0.0000e+00\n",
      "Epoch 00001: val_IoU improved from -inf to 0.00000, saving model to TEST/000001.h5\n",
      "92/92 [==============================] - 322s 4s/step - loss: 2.1974 - IoU: 0.0149 - val_loss: 2.4404 - val_IoU: 0.0000e+00\n",
      "Epoch 2/300\n",
      "18/92 [====>.........................] - ETA: 1:45 - loss: 1.8639 - IoU: 0.0325"
     ]
    }
   ],
   "source": [
    "#hist = model.fit_generator(data_gen, validation_data=(valid_x, valid_y), epochs=par.n_epochs, steps_per_epoch=par.n_batch, callbacks=[cp_cb])\n",
    "hist = model.fit_generator(train_data_gen,\n",
    "                           epochs=n_epochs,\n",
    "                           steps_per_epoch=len(train_data_gen),\n",
    "                           validation_data=valid_data_gen,\n",
    "                           validation_steps=len(valid_data_gen),\n",
    "                           #shuffle = False,\n",
    "                           workers=8,\n",
    "                           use_multiprocessing=True,\n",
    "                           callbacks=[cp_cb])\n",
    "#hist = model.fit_generator(data_gen, epochs=par.n_epochs, steps_per_epoch=par.n_batch, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(hist.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(hist.history[\"IoU\"], label=\"IoU\")\n",
    "plt.plot(hist.history[\"val_IoU\"], label=\"val_IoU\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(out_dir,'losscurve.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(out_dir,'final_epoch.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sorted(hist.history.keys()):\n",
    "    np.savetxt(os.path.join(out_dir,key+'.txt'),np.array(hist.history[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
