{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(visible_device_list=\"0\", allow_growth=True)\n",
    "config = tf.compat.v1.ConfigProto(gpu_options = gpu_options)\n",
    "tf.compat.v1.enable_eager_execution(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import deeplab_v3plus\n",
    "from image_utils import make_x_from_image_paths,make_y_from_image_paths,convert_y_to_image_array\n",
    "from data_gen import make_data_gen\n",
    "from params import params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'params' from '/stg318/User/taniguchi-j/DeepLab_v3plus/params.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(sys.modules['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = params()\n",
    "par.n_categories = 21\n",
    "par.image_size = (512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_img_dir = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/SegmentationClass\"\n",
    "img_dir = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/JPEGImages\"\n",
    "train_set_path = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt\"\n",
    "valid_set_path = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt\"\n",
    "\n",
    "with open(train_set_path) as f:\n",
    "    train_img_names = f.read().split(\"\\n\")[:-1]\n",
    "with open(valid_set_path) as f:\n",
    "    valid_img_names = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "\n",
    "par.img_paths = [os.path.join(img_dir,train_img_names[i]) + \".jpg\" for i in range(len(train_img_names))]\n",
    "par.seg_img_paths = [os.path.join(seg_img_dir,train_img_names[i]) + \".png\" for i in range(len(train_img_names))]\n",
    "\n",
    "valid_x_paths = [os.path.join(img_dir,valid_img_names[i]) + \".jpg\" for i in range(len(valid_img_names))]\n",
    "valid_y_paths = [os.path.join(seg_img_dir,valid_img_names[i]) + \".png\" for i in range(len(valid_img_names))]\n",
    "valid_x = make_x_from_image_paths(valid_x_paths, par) /255\n",
    "valid_y = make_y_from_image_paths(valid_y_paths, par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "par.batch_size=8\n",
    "par.n_epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = make_data_gen(par)\n",
    "par.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deeplab_v3plus(par)\n",
    "loss_function = tf.keras.losses.categorical_crossentropy\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=opt, loss=loss_function, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './saved_model/{epoch:06d}.hdf5'\n",
    "cp_cb = keras.callbacks.ModelCheckpoint(filepath, \n",
    "                                        monitor='val_loss', \n",
    "                                        verbose=0, \n",
    "                                        save_best_only=True, \n",
    "                                        save_weights_only=False, \n",
    "                                        mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1125 14:48:03.554447 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 14:48:14.980512 140736185191632 deprecation.py:323] From /home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/183 [============================>.] - ETA: 1s - loss: 2.7057 - acc: 0.4939"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 14:52:00.600784 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 2.3103 - acc: 0.7432\n",
      "Epoch 1/1000\n",
      "183/183 [==============================] - 404s 2s/step - loss: 2.7045 - acc: 0.4949 - val_loss: 2.3362 - val_acc: 0.7432\n",
      "Epoch 2/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 2.3898 - acc: 0.6251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 14:58:31.184368 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 173s 59ms/sample - loss: 1.9378 - acc: 0.7432\n",
      "183/183 [==============================] - 400s 2s/step - loss: 2.3899 - acc: 0.6251 - val_loss: 1.9806 - val_acc: 0.7432\n",
      "Epoch 3/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 2.1551 - acc: 0.6664"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 15:05:06.336912 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 169s 58ms/sample - loss: 3.4508 - acc: 0.3534\n",
      "183/183 [==============================] - 388s 2s/step - loss: 2.1553 - acc: 0.6663 - val_loss: 3.3430 - val_acc: 0.3534\n",
      "Epoch 4/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 2.0212 - acc: 0.6871"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 15:11:38.601627 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 169s 58ms/sample - loss: 1.9828 - acc: 0.6651\n",
      "183/183 [==============================] - 392s 2s/step - loss: 2.0195 - acc: 0.6875 - val_loss: 2.0232 - val_acc: 0.6651\n",
      "Epoch 5/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.9064 - acc: 0.6695"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 15:18:07.928600 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 2.5588 - acc: 0.6256\n",
      "183/183 [==============================] - 379s 2s/step - loss: 1.9065 - acc: 0.6696 - val_loss: 2.2596 - val_acc: 0.6256\n",
      "Epoch 1/1000\n",
      "Epoch 6/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.7445 - acc: 0.7012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 15:24:25.705840 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 1.7821 - acc: 0.6893\n",
      "Epoch 1/1000\n",
      "183/183 [==============================] - 380s 2s/step - loss: 1.7438 - acc: 0.7013 - val_loss: 1.8243 - val_acc: 0.6893\n",
      "Epoch 7/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.6520 - acc: 0.7134"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 15:30:44.403586 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 178s 61ms/sample - loss: 2.1376 - acc: 0.6516\n",
      "183/183 [==============================] - 396s 2s/step - loss: 1.6509 - acc: 0.7135 - val_loss: 1.9913 - val_acc: 0.6516\n",
      "Epoch 8/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.5620 - acc: 0.6937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 15:37:23.558099 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 2.1450 - acc: 0.6512\n",
      "183/183 [==============================] - 380s 2s/step - loss: 1.5609 - acc: 0.6942 - val_loss: 1.9928 - val_acc: 0.6512\n",
      "Epoch 9/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.4751 - acc: 0.7247"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 15:43:46.109157 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 2.3049 - acc: 0.5960\n",
      "183/183 [==============================] - 383s 2s/step - loss: 1.4746 - acc: 0.7248 - val_loss: 3.0082 - val_acc: 0.5960\n",
      "\n",
      "Epoch 10/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.3541 - acc: 0.7512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 15:50:06.411449 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 3.1376 - acc: 0.6593\n",
      "183/183 [==============================] - 380s 2s/step - loss: 1.3548 - acc: 0.7508 - val_loss: 2.6746 - val_acc: 0.6593\n",
      "Epoch 11/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.4118 - acc: 0.7186"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 15:56:26.171342 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 3.4493 - acc: 0.6291\n",
      "183/183 [==============================] - 386s 2s/step - loss: 1.4123 - acc: 0.7183 - val_loss: 2.7342 - val_acc: 0.6291\n",
      "Epoch 12/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.3235 - acc: 0.7258"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 16:02:54.426486 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 2.1941 - acc: 0.6358\n",
      "183/183 [==============================] - 385s 2s/step - loss: 1.3225 - acc: 0.7261 - val_loss: 2.2141 - val_acc: 0.6358\n",
      "Epoch 1/1000\n",
      "Epoch 13/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.2394 - acc: 0.7404"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 16:09:16.000434 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.1272 - acc: 0.7399\n",
      "183/183 [==============================] - 381s 2s/step - loss: 1.2391 - acc: 0.7403 - val_loss: 1.2623 - val_acc: 0.7399\n",
      "Epoch 14/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.1744 - acc: 0.7543"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 16:15:41.024956 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 178s 61ms/sample - loss: 1.1451 - acc: 0.7313\n",
      "183/183 [==============================] - 400s 2s/step - loss: 1.1724 - acc: 0.7549 - val_loss: 1.2801 - val_acc: 0.7313\n",
      "\n",
      "Epoch 15/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.1328 - acc: 0.7546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 16:22:20.253066 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.1165 - acc: 0.7419\n",
      "Epoch 1/1000\n",
      "183/183 [==============================] - 385s 2s/step - loss: 1.1322 - acc: 0.7548 - val_loss: 1.2149 - val_acc: 0.7419\n",
      "Epoch 16/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.1169 - acc: 0.7547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 16:28:42.779475 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.3599 - acc: 0.7035\n",
      "183/183 [==============================] - 379s 2s/step - loss: 1.1144 - acc: 0.7556 - val_loss: 1.3492 - val_acc: 0.7035\n",
      "Epoch 17/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.1135 - acc: 0.7499"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 16:35:03.289395 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 1.3334 - acc: 0.7326\n",
      "183/183 [==============================] - 385s 2s/step - loss: 1.1136 - acc: 0.7501 - val_loss: 1.3279 - val_acc: 0.7326\n",
      "Epoch 18/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.0772 - acc: 0.7527"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 16:41:27.255467 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 172s 59ms/sample - loss: 1.5969 - acc: 0.6658\n",
      "183/183 [==============================] - 392s 2s/step - loss: 1.0778 - acc: 0.7529 - val_loss: 1.8259 - val_acc: 0.6658\n",
      "Epoch 19/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.0812 - acc: 0.7572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 16:48:05.255118 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 55ms/sample - loss: 1.5584 - acc: 0.6782\n",
      "183/183 [==============================] - 387s 2s/step - loss: 1.0788 - acc: 0.7580 - val_loss: 1.6430 - val_acc: 0.6782\n",
      "Epoch 20/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.1425 - acc: 0.7313"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 16:54:35.892164 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 55ms/sample - loss: 1.4658 - acc: 0.7116\n",
      "183/183 [==============================] - 391s 2s/step - loss: 1.1402 - acc: 0.7318 - val_loss: 1.4965 - val_acc: 0.7116\n",
      "Epoch 1/1000\n",
      "Epoch 21/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.0571 - acc: 0.7631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 17:00:57.791676 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.2358 - acc: 0.7247\n",
      "183/183 [==============================] - 381s 2s/step - loss: 1.0577 - acc: 0.7627 - val_loss: 1.3113 - val_acc: 0.7247\n",
      "Epoch 1/1000\n",
      "Epoch 22/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.1444 - acc: 0.7289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 17:07:19.934090 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 174s 60ms/sample - loss: 2.4080 - acc: 0.6869\n",
      "183/183 [==============================] - 396s 2s/step - loss: 1.1449 - acc: 0.7289 - val_loss: 1.9819 - val_acc: 0.6869\n",
      "Epoch 23/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.0757 - acc: 0.7485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 17:13:56.611690 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 3.1758 - acc: 0.6325\n",
      "183/183 [==============================] - 383s 2s/step - loss: 1.0742 - acc: 0.7490 - val_loss: 2.9671 - val_acc: 0.6325\n",
      "Epoch 24/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.0273 - acc: 0.7531"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 17:20:18.818024 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 55ms/sample - loss: 1.2996 - acc: 0.6583\n",
      "183/183 [==============================] - 383s 2s/step - loss: 1.0256 - acc: 0.7537 - val_loss: 1.4242 - val_acc: 0.6583\n",
      "Epoch 25/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.0920 - acc: 0.7385"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 17:26:44.109868 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 58ms/sample - loss: 1.7338 - acc: 0.6511\n",
      "183/183 [==============================] - 392s 2s/step - loss: 1.0917 - acc: 0.7387 - val_loss: 1.5439 - val_acc: 0.6511\n",
      "Epoch 1/1000\n",
      "Epoch 26/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.0939 - acc: 0.7252"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 17:33:15.501889 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.1664 - acc: 0.7327\n",
      "183/183 [==============================] - 386s 2s/step - loss: 1.0928 - acc: 0.7257 - val_loss: 1.1937 - val_acc: 0.7327\n",
      "Epoch 27/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9581 - acc: 0.7700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 17:39:40.151007 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.5531 - acc: 0.6572\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.9583 - acc: 0.7697 - val_loss: 1.9882 - val_acc: 0.6572\n",
      "Epoch 28/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.0296 - acc: 0.7552"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 17:46:00.949144 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.1378 - acc: 0.7248\n",
      "183/183 [==============================] - 380s 2s/step - loss: 1.0292 - acc: 0.7555 - val_loss: 1.2687 - val_acc: 0.7248\n",
      "Epoch 1/1000Epoch 29/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.0555 - acc: 0.7532"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 17:52:20.912477 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 1.3881 - acc: 0.6712\n",
      "183/183 [==============================] - 379s 2s/step - loss: 1.0551 - acc: 0.7533 - val_loss: 1.6941 - val_acc: 0.6712\n",
      "Epoch 30/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9730 - acc: 0.7633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 17:58:40.150704 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 169s 58ms/sample - loss: 2.5303 - acc: 0.6402\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.9741 - acc: 0.7625 - val_loss: 2.1288 - val_acc: 0.6402\n",
      "Epoch 31/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9642 - acc: 0.7602"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 18:05:14.089403 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 174s 60ms/sample - loss: 2.4707 - acc: 0.6464\n",
      "183/183 [==============================] - 399s 2s/step - loss: 0.9632 - acc: 0.7607 - val_loss: 1.9178 - val_acc: 0.6464\n",
      "Epoch 32/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.0334 - acc: 0.7428"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 18:11:49.624552 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.1562 - acc: 0.7345\n",
      "183/183 [==============================] - 382s 2s/step - loss: 1.0319 - acc: 0.7431 - val_loss: 1.2648 - val_acc: 0.7345\n",
      "Epoch 33/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.0261 - acc: 0.7421"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 18:18:07.908837 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.0930 - acc: 0.7196\n",
      "183/183 [==============================] - 378s 2s/step - loss: 1.0251 - acc: 0.7421 - val_loss: 1.2121 - val_acc: 0.7196\n",
      "Epoch 34/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9592 - acc: 0.7508"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 18:24:27.900247 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 1.0779 - acc: 0.7262\n",
      "Epoch 1/1000\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.9592 - acc: 0.7505 - val_loss: 1.1754 - val_acc: 0.7262\n",
      "Epoch 35/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.0063 - acc: 0.7516"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 18:30:54.809507 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.6106 - acc: 0.6762\n",
      "183/183 [==============================] - 378s 2s/step - loss: 1.0078 - acc: 0.7513 - val_loss: 1.5918 - val_acc: 0.6762\n",
      "Epoch 1/1000\n",
      "Epoch 36/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 1.0045 - acc: 0.7536"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 18:37:13.324074 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.1435 - acc: 0.7076\n",
      "183/183 [==============================] - 380s 2s/step - loss: 1.0041 - acc: 0.7538 - val_loss: 1.2562 - val_acc: 0.7076\n",
      "Epoch 1/1000\n",
      "Epoch 37/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9883 - acc: 0.7546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 18:43:33.937684 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 176s 60ms/sample - loss: 1.4322 - acc: 0.6157\n",
      "183/183 [==============================] - 396s 2s/step - loss: 0.9903 - acc: 0.7541 - val_loss: 1.5259 - val_acc: 0.6157\n",
      "Epoch 38/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9969 - acc: 0.7451"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 18:50:14.841442 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 55ms/sample - loss: 1.2130 - acc: 0.6911\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.9963 - acc: 0.7455 - val_loss: 1.2707 - val_acc: 0.6911\n",
      "Epoch 39/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9213 - acc: 0.7720"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 18:56:36.873716 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 158s 54ms/sample - loss: 1.1692 - acc: 0.6880\n",
      "183/183 [==============================] - 378s 2s/step - loss: 0.9192 - acc: 0.7725 - val_loss: 1.4416 - val_acc: 0.6880\n",
      "Epoch 40/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9263 - acc: 0.7618"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 19:02:54.522130 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 1.9405 - acc: 0.6357\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.9239 - acc: 0.7625 - val_loss: 2.1835 - val_acc: 0.6357\n",
      "Epoch 41/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9221 - acc: 0.7602"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 19:09:14.183037 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 1.2626 - acc: 0.6340\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.9225 - acc: 0.7599 - val_loss: 1.3582 - val_acc: 0.6340\n",
      "Epoch 1/1000\n",
      "Epoch 42/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8811 - acc: 0.7764"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 19:15:32.724293 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.6920 - acc: 0.6460\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.8793 - acc: 0.7769 - val_loss: 1.5220 - val_acc: 0.6460\n",
      "Epoch 43/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9917 - acc: 0.7428"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 19:21:53.220121 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.0258 - acc: 0.6798\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.9908 - acc: 0.7429 - val_loss: 1.3596 - val_acc: 0.6798\n",
      "Epoch 1/1000\n",
      "Epoch 44/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9035 - acc: 0.7712"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 19:28:22.556105 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.1357 - acc: 0.7062\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.9025 - acc: 0.7715 - val_loss: 1.3209 - val_acc: 0.7062\n",
      "Epoch 45/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9982 - acc: 0.7398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 19:34:42.978778 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 180s 62ms/sample - loss: 1.3829 - acc: 0.6527\n",
      "183/183 [==============================] - 400s 2s/step - loss: 0.9973 - acc: 0.7398 - val_loss: 1.3591 - val_acc: 0.6527\n",
      "Epoch 46/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9229 - acc: 0.7556"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 19:41:35.264254 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.8897 - acc: 0.6090\n",
      "183/183 [==============================] - 392s 2s/step - loss: 0.9209 - acc: 0.7563 - val_loss: 1.8925 - val_acc: 0.6090\n",
      "Epoch 1/1000\n",
      "Epoch 47/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8078 - acc: 0.7889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 19:47:54.429368 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 173s 59ms/sample - loss: 1.1653 - acc: 0.6902\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.8066 - acc: 0.7892 - val_loss: 1.5002 - val_acc: 0.6902\n",
      "Epoch 48/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8999 - acc: 0.7591"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 19:54:31.289553 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 174s 60ms/sample - loss: 1.0253 - acc: 0.7260\n",
      "183/183 [==============================] - 400s 2s/step - loss: 0.8983 - acc: 0.7597 - val_loss: 1.1502 - val_acc: 0.7260\n",
      "Epoch 49/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8483 - acc: 0.7702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 20:01:09.572324 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 1.0579 - acc: 0.7322\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.8472 - acc: 0.7705 - val_loss: 1.0635 - val_acc: 0.7322\n",
      "Epoch 50/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8288 - acc: 0.7813"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 20:07:31.145799 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 1.2126 - acc: 0.6883\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.8292 - acc: 0.7814 - val_loss: 1.2436 - val_acc: 0.6883\n",
      "Epoch 51/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8690 - acc: 0.7781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 20:13:55.996385 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 57ms/sample - loss: 2.2404 - acc: 0.5863\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.8664 - acc: 0.7789 - val_loss: 2.0202 - val_acc: 0.5863\n",
      "Epoch 1/1000\n",
      "Epoch 52/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9500 - acc: 0.7489"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 20:20:25.248875 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 1.0565 - acc: 0.7344\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.9492 - acc: 0.7488 - val_loss: 1.0726 - val_acc: 0.7344\n",
      "Epoch 53/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8301 - acc: 0.7767"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 20:26:44.684082 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 1.1234 - acc: 0.7114\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.8293 - acc: 0.7771 - val_loss: 1.1241 - val_acc: 0.7114\n",
      "Epoch 1/1000\n",
      "Epoch 54/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9672 - acc: 0.7417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 20:33:14.074141 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 1.0633 - acc: 0.6987\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.9671 - acc: 0.7414 - val_loss: 1.2575 - val_acc: 0.6987\n",
      "Epoch 55/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9182 - acc: 0.7591"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 20:39:36.148511 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 158s 54ms/sample - loss: 1.0252 - acc: 0.7067\n",
      "183/183 [==============================] - 378s 2s/step - loss: 0.9217 - acc: 0.7580 - val_loss: 1.2379 - val_acc: 0.7067\n",
      "Epoch 56/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8374 - acc: 0.7757"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 20:45:53.967787 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 0.9602 - acc: 0.7276\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.8364 - acc: 0.7759 - val_loss: 1.1094 - val_acc: 0.7276\n",
      "Epoch 57/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8159 - acc: 0.7801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 20:52:14.139327 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.0278 - acc: 0.6935\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.8166 - acc: 0.7800 - val_loss: 1.2684 - val_acc: 0.6935\n",
      "Epoch 58/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8639 - acc: 0.7697"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 20:58:35.247753 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.2589 - acc: 0.6618\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.8622 - acc: 0.7701 - val_loss: 1.3106 - val_acc: 0.6618\n",
      "Epoch 59/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8278 - acc: 0.7761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 21:04:57.595343 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 0.9778 - acc: 0.7340\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.8316 - acc: 0.7753 - val_loss: 1.1392 - val_acc: 0.7340\n",
      "Epoch 60/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8649 - acc: 0.7687"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 21:11:21.581930 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 1.1175 - acc: 0.7110\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.8636 - acc: 0.7691 - val_loss: 1.3153 - val_acc: 0.7110\n",
      "Epoch 61/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8417 - acc: 0.7741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 21:17:51.033889 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.1330 - acc: 0.6995\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.8467 - acc: 0.7724 - val_loss: 1.4509 - val_acc: 0.6995\n",
      "Epoch 62/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.9232 - acc: 0.7552"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 21:24:12.746756 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8627 - acc: 0.7547\n",
      "Epoch 1/1000\n",
      "183/183 [==============================] - 385s 2s/step - loss: 0.9222 - acc: 0.7553 - val_loss: 0.9669 - val_acc: 0.7547\n",
      "Epoch 63/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8402 - acc: 0.7697"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 21:30:35.615671 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.1189 - acc: 0.7209\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.8400 - acc: 0.7697 - val_loss: 1.1731 - val_acc: 0.7209\n",
      "Epoch 64/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7654 - acc: 0.7898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 21:36:56.265732 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8977 - acc: 0.7500\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.7643 - acc: 0.7902 - val_loss: 0.9904 - val_acc: 0.7500\n",
      "\n",
      "Epoch 65/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7927 - acc: 0.7803"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 21:43:15.004028 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 57ms/sample - loss: 1.0498 - acc: 0.7305\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.7929 - acc: 0.7802 - val_loss: 1.0461 - val_acc: 0.7305\n",
      "Epoch 66/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7706 - acc: 0.7856"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 21:49:42.024996 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8465 - acc: 0.7664\n",
      "Epoch 1/1000\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.7698 - acc: 0.7860 - val_loss: 0.9422 - val_acc: 0.7664\n",
      "Epoch 67/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7946 - acc: 0.7824"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 21:56:04.623088 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8170 - acc: 0.7583\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.7959 - acc: 0.7821 - val_loss: 0.9423 - val_acc: 0.7583\n",
      "Epoch 68/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7826 - acc: 0.7828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 22:02:23.961119 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 0.8123 - acc: 0.7428\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.7828 - acc: 0.7828 - val_loss: 1.0178 - val_acc: 0.7428\n",
      "Epoch 69/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8156 - acc: 0.7787"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 22:09:02.877151 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.9236 - acc: 0.7521\n",
      "183/183 [==============================] - 392s 2s/step - loss: 0.8172 - acc: 0.7787 - val_loss: 0.9759 - val_acc: 0.7521\n",
      "Epoch 70/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8185 - acc: 0.7839"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 22:15:41.081415 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.9518 - acc: 0.7378\n",
      "183/183 [==============================] - 399s 2s/step - loss: 0.8166 - acc: 0.7844 - val_loss: 1.0625 - val_acc: 0.7378\n",
      "Epoch 1/1000\n",
      "Epoch 71/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7279 - acc: 0.7993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 22:22:19.002461 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 178s 61ms/sample - loss: 0.9657 - acc: 0.7241\n",
      "183/183 [==============================] - 415s 2s/step - loss: 0.7291 - acc: 0.7985 - val_loss: 1.0955 - val_acc: 0.7241\n",
      "Epoch 72/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7359 - acc: 0.7903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 22:28:59.511151 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 55ms/sample - loss: 1.0703 - acc: 0.7025\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.7355 - acc: 0.7906 - val_loss: 1.4388 - val_acc: 0.7025\n",
      "Epoch 73/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7618 - acc: 0.7860"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 22:35:22.352710 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 1.0105 - acc: 0.7229\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.7646 - acc: 0.7852 - val_loss: 1.2184 - val_acc: 0.7229\n",
      "Epoch 74/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7423 - acc: 0.7846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 22:41:54.889574 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 180s 61ms/sample - loss: 0.8629 - acc: 0.7617\n",
      "Epoch 1/1000\n",
      "183/183 [==============================] - 408s 2s/step - loss: 0.7412 - acc: 0.7849 - val_loss: 0.9048 - val_acc: 0.7617\n",
      "Epoch 75/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7348 - acc: 0.7956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 22:48:36.491431 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8419 - acc: 0.7663\n",
      "Epoch 1/1000\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.7333 - acc: 0.7961 - val_loss: 0.8479 - val_acc: 0.7663\n",
      "Epoch 76/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7441 - acc: 0.7969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 22:55:00.813463 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 56ms/sample - loss: 1.2074 - acc: 0.6960\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.7431 - acc: 0.7971 - val_loss: 1.6746 - val_acc: 0.6960\n",
      "Epoch 77/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7423 - acc: 0.7926"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 23:01:26.790363 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.2201 - acc: 0.7014\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.7425 - acc: 0.7926 - val_loss: 1.4508 - val_acc: 0.7014\n",
      "Epoch 78/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7484 - acc: 0.7884"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 23:07:46.563049 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 170s 58ms/sample - loss: 0.8214 - acc: 0.7274\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.7476 - acc: 0.7887 - val_loss: 1.1544 - val_acc: 0.7274\n",
      "Epoch 79/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7709 - acc: 0.7850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 23:14:18.993702 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 169s 58ms/sample - loss: 1.0638 - acc: 0.7167\n",
      "183/183 [==============================] - 391s 2s/step - loss: 0.7722 - acc: 0.7845 - val_loss: 1.0296 - val_acc: 0.7167\n",
      "Epoch 80/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.8046 - acc: 0.7734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 23:20:48.196044 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 56ms/sample - loss: 0.9853 - acc: 0.7523\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.8025 - acc: 0.7741 - val_loss: 0.9753 - val_acc: 0.7523\n",
      "Epoch 1/1000\n",
      "Epoch 81/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7097 - acc: 0.7960"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 23:27:16.866895 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.8480 - acc: 0.7642\n",
      "183/183 [==============================] - 391s 2s/step - loss: 0.7091 - acc: 0.7963 - val_loss: 0.8752 - val_acc: 0.7642\n",
      "Epoch 82/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7550 - acc: 0.7847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 23:33:43.019626 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.9363 - acc: 0.7613\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.7572 - acc: 0.7842 - val_loss: 0.9882 - val_acc: 0.7613\n",
      "Epoch 83/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7364 - acc: 0.7879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 23:40:04.694659 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 0.9292 - acc: 0.7056\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.7359 - acc: 0.7883 - val_loss: 1.0713 - val_acc: 0.7056\n",
      "Epoch 84/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6339 - acc: 0.8181"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 23:46:35.841491 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 0.8714 - acc: 0.7581\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.6336 - acc: 0.8180 - val_loss: 0.8985 - val_acc: 0.7581\n",
      "Epoch 1/1000\n",
      "Epoch 85/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6705 - acc: 0.8088"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 23:53:02.000608 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.7593 - acc: 0.7730\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.6694 - acc: 0.8092 - val_loss: 0.8481 - val_acc: 0.7730\n",
      "Epoch 86/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.7044 - acc: 0.7976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1125 23:59:20.333621 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 56ms/sample - loss: 0.8744 - acc: 0.7426\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.7040 - acc: 0.7978 - val_loss: 0.9104 - val_acc: 0.7426\n",
      "Epoch 1/1000Epoch 87/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6445 - acc: 0.8180"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 00:05:42.492030 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.0337 - acc: 0.7248\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.6455 - acc: 0.8177 - val_loss: 1.1037 - val_acc: 0.7248\n",
      "Epoch 1/1000\n",
      "Epoch 88/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6217 - acc: 0.8217"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 00:12:08.694221 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.8842 - acc: 0.7525\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.6202 - acc: 0.8221 - val_loss: 0.8987 - val_acc: 0.7525\n",
      "Epoch 89/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6651 - acc: 0.8032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 00:18:45.060954 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.3035 - acc: 0.6823\n",
      "183/183 [==============================] - 397s 2s/step - loss: 0.6652 - acc: 0.8030 - val_loss: 1.2425 - val_acc: 0.6823\n",
      "Epoch 90/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5978 - acc: 0.8223"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 00:25:10.078295 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 158s 54ms/sample - loss: 0.8977 - acc: 0.7497\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.5981 - acc: 0.8223 - val_loss: 0.9835 - val_acc: 0.7497\n",
      "Epoch 91/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6432 - acc: 0.8137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 00:31:27.885328 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 179s 61ms/sample - loss: 0.8839 - acc: 0.7492\n",
      "183/183 [==============================] - 398s 2s/step - loss: 0.6433 - acc: 0.8136 - val_loss: 0.9911 - val_acc: 0.7492\n",
      "Epoch 92/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6291 - acc: 0.8207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 00:38:18.596405 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 170s 58ms/sample - loss: 0.9105 - acc: 0.7498\n",
      "183/183 [==============================] - 402s 2s/step - loss: 0.6297 - acc: 0.8206 - val_loss: 0.9068 - val_acc: 0.7498\n",
      "Epoch 93/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6368 - acc: 0.8198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 00:45:05.298165 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 176s 60ms/sample - loss: 0.8453 - acc: 0.7629\n",
      "183/183 [==============================] - 413s 2s/step - loss: 0.6379 - acc: 0.8194 - val_loss: 0.9454 - val_acc: 0.7629\n",
      "Epoch 94/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6699 - acc: 0.8069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 00:51:50.718264 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.7595 - acc: 0.7678\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.6686 - acc: 0.8073 - val_loss: 0.8806 - val_acc: 0.7678\n",
      "\n",
      "Epoch 95/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6437 - acc: 0.8191"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 00:58:20.559297 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.9327 - acc: 0.7298\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.6430 - acc: 0.8192 - val_loss: 0.9680 - val_acc: 0.7298\n",
      "Epoch 1/1000\n",
      "Epoch 96/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5713 - acc: 0.8369"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 01:04:47.763558 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 58ms/sample - loss: 0.8728 - acc: 0.7482\n",
      "183/183 [==============================] - 392s 2s/step - loss: 0.5708 - acc: 0.8371 - val_loss: 1.0446 - val_acc: 0.7482\n",
      "Epoch 97/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6302 - acc: 0.8161"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 01:11:19.189440 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 0.8115 - acc: 0.7748\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.6300 - acc: 0.8163 - val_loss: 0.8311 - val_acc: 0.7748\n",
      "Epoch 98/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6423 - acc: 0.8107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 01:17:50.669056 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 158s 54ms/sample - loss: 0.7744 - acc: 0.7551\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.6429 - acc: 0.8106 - val_loss: 0.8945 - val_acc: 0.7551\n",
      "Epoch 1/1000\n",
      "Epoch 99/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5482 - acc: 0.8415"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 01:24:17.651787 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.9362 - acc: 0.7320\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.5480 - acc: 0.8414 - val_loss: 1.1016 - val_acc: 0.7320\n",
      "Epoch 1/1000\n",
      "Epoch 100/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5797 - acc: 0.8334"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 01:30:40.749318 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.0271 - acc: 0.7170\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.5783 - acc: 0.8338 - val_loss: 1.1846 - val_acc: 0.7170\n",
      "Epoch 101/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6738 - acc: 0.8050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 01:37:05.186902 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 171s 58ms/sample - loss: 0.8209 - acc: 0.7689\n",
      "183/183 [==============================] - 394s 2s/step - loss: 0.6731 - acc: 0.8053 - val_loss: 0.8729 - val_acc: 0.7689\n",
      "Epoch 102/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5726 - acc: 0.8363"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 01:43:39.498057 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.8753 - acc: 0.7620\n",
      "183/183 [==============================] - 385s 2s/step - loss: 0.5723 - acc: 0.8363 - val_loss: 0.8714 - val_acc: 0.7620\n",
      "Epoch 1/1000\n",
      "Epoch 103/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6127 - acc: 0.8249"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 01:50:01.323515 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.8336 - acc: 0.7695\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.6121 - acc: 0.8250 - val_loss: 0.9047 - val_acc: 0.7695\n",
      "Epoch 104/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6054 - acc: 0.8220"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 01:56:24.867911 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 179s 61ms/sample - loss: 0.8754 - acc: 0.7346\n",
      "183/183 [==============================] - 401s 2s/step - loss: 0.6049 - acc: 0.8222 - val_loss: 0.9373 - val_acc: 0.7346\n",
      "Epoch 105/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5590 - acc: 0.8374"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 02:03:05.704302 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8752 - acc: 0.7659\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.5589 - acc: 0.8372 - val_loss: 0.8476 - val_acc: 0.7659\n",
      "Epoch 1/1000\n",
      "Epoch 106/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5740 - acc: 0.8330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 02:09:27.924123 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8253 - acc: 0.7642\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.5740 - acc: 0.8329 - val_loss: 0.9337 - val_acc: 0.7642\n",
      "Epoch 1/1000\n",
      "Epoch 107/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6052 - acc: 0.8224"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 02:15:48.880406 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 178s 61ms/sample - loss: 0.8424 - acc: 0.7620\n",
      "183/183 [==============================] - 399s 2s/step - loss: 0.6048 - acc: 0.8226 - val_loss: 0.8748 - val_acc: 0.7620\n",
      "Epoch 108/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5849 - acc: 0.8294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 02:22:39.261539 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 181s 62ms/sample - loss: 0.7780 - acc: 0.7783\n",
      "183/183 [==============================] - 414s 2s/step - loss: 0.5874 - acc: 0.8287 - val_loss: 0.8315 - val_acc: 0.7783\n",
      "Epoch 109/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5533 - acc: 0.8396"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 02:29:34.499848 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 0.7976 - acc: 0.7556\n",
      "183/183 [==============================] - 401s 2s/step - loss: 0.5537 - acc: 0.8391 - val_loss: 0.8978 - val_acc: 0.7556\n",
      "Epoch 110/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6015 - acc: 0.8267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 02:36:07.374606 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 173s 59ms/sample - loss: 0.9413 - acc: 0.7415\n",
      "183/183 [==============================] - 399s 2s/step - loss: 0.6031 - acc: 0.8260 - val_loss: 0.9378 - val_acc: 0.7415\n",
      "Epoch 111/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5693 - acc: 0.8342"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 02:42:46.352910 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 57ms/sample - loss: 0.8424 - acc: 0.7797\n",
      "183/183 [==============================] - 399s 2s/step - loss: 0.5716 - acc: 0.8335 - val_loss: 0.7791 - val_acc: 0.7797\n",
      "Epoch 112/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6689 - acc: 0.8076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 02:49:30.134287 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 172s 59ms/sample - loss: 1.3517 - acc: 0.6762\n",
      "183/183 [==============================] - 403s 2s/step - loss: 0.6688 - acc: 0.8077 - val_loss: 1.1958 - val_acc: 0.6762\n",
      "Epoch 113/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5764 - acc: 0.8295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 02:56:03.530088 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.8190 - acc: 0.7470\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.5750 - acc: 0.8299 - val_loss: 0.9324 - val_acc: 0.7470\n",
      "Epoch 114/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5761 - acc: 0.8302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 03:02:25.837901 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.8464 - acc: 0.7595\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.5755 - acc: 0.8304 - val_loss: 0.9207 - val_acc: 0.7595\n",
      "Epoch 115/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5660 - acc: 0.8342"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 03:08:48.218660 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 0.7196 - acc: 0.7746\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.5650 - acc: 0.8346 - val_loss: 0.7896 - val_acc: 0.7746\n",
      "Epoch 116/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5544 - acc: 0.8436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 03:15:13.163887 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 169s 58ms/sample - loss: 0.6959 - acc: 0.7788\n",
      "183/183 [==============================] - 395s 2s/step - loss: 0.5545 - acc: 0.8434 - val_loss: 0.8048 - val_acc: 0.7788\n",
      "Epoch 1/1000\n",
      "Epoch 117/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5964 - acc: 0.8227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 03:21:49.383043 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 165s 56ms/sample - loss: 0.8162 - acc: 0.7805\n",
      "183/183 [==============================] - 391s 2s/step - loss: 0.5976 - acc: 0.8225 - val_loss: 0.8161 - val_acc: 0.7805\n",
      "Epoch 118/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.6237 - acc: 0.8211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 03:28:15.036435 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 58ms/sample - loss: 0.9139 - acc: 0.7627\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.6232 - acc: 0.8213 - val_loss: 1.0686 - val_acc: 0.7627\n",
      "Epoch 119/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5911 - acc: 0.8281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 03:34:46.672335 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 173s 59ms/sample - loss: 0.8073 - acc: 0.7699\n",
      "183/183 [==============================] - 396s 2s/step - loss: 0.5913 - acc: 0.8281 - val_loss: 0.8887 - val_acc: 0.7699\n",
      "Epoch 120/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5842 - acc: 0.8342"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 03:41:29.095123 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 172s 59ms/sample - loss: 0.7543 - acc: 0.7753\n",
      "183/183 [==============================] - 402s 2s/step - loss: 0.5834 - acc: 0.8345 - val_loss: 0.8062 - val_acc: 0.7753\n",
      "Epoch 121/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4804 - acc: 0.8595"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 03:48:13.683572 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.8998 - acc: 0.7679\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.4821 - acc: 0.8590 - val_loss: 0.9486 - val_acc: 0.7679\n",
      "Epoch 1/1000\n",
      "Epoch 122/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5400 - acc: 0.8388"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 03:54:34.835711 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.9654 - acc: 0.7529\n",
      "183/183 [==============================] - 385s 2s/step - loss: 0.5393 - acc: 0.8389 - val_loss: 0.9841 - val_acc: 0.7529\n",
      "Epoch 1/1000\n",
      "Epoch 123/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5530 - acc: 0.8396"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 04:01:07.404416 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 55ms/sample - loss: 0.7679 - acc: 0.7810\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.5518 - acc: 0.8400 - val_loss: 0.8272 - val_acc: 0.7810\n",
      "Epoch 124/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5429 - acc: 0.8392"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 04:07:42.982027 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.7346 - acc: 0.7856\n",
      "183/183 [==============================] - 394s 2s/step - loss: 0.5422 - acc: 0.8394 - val_loss: 0.7994 - val_acc: 0.7856\n",
      "Epoch 125/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5581 - acc: 0.8346"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 04:14:11.426024 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 177s 61ms/sample - loss: 0.7915 - acc: 0.7555\n",
      "183/183 [==============================] - 406s 2s/step - loss: 0.5581 - acc: 0.8347 - val_loss: 0.8375 - val_acc: 0.7555\n",
      "Epoch 1/1000\n",
      "Epoch 126/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5212 - acc: 0.8497"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 04:20:49.140099 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 0.7898 - acc: 0.7547\n",
      "183/183 [==============================] - 388s 2s/step - loss: 0.5214 - acc: 0.8496 - val_loss: 0.8738 - val_acc: 0.7547\n",
      "Epoch 127/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5236 - acc: 0.8462"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 04:27:19.242337 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 56ms/sample - loss: 0.7450 - acc: 0.7815\n",
      "183/183 [==============================] - 385s 2s/step - loss: 0.5224 - acc: 0.8466 - val_loss: 0.8413 - val_acc: 0.7815\n",
      "Epoch 128/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5369 - acc: 0.8442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 04:33:42.793339 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 170s 58ms/sample - loss: 0.6116 - acc: 0.7956\n",
      "183/183 [==============================] - 395s 2s/step - loss: 0.5362 - acc: 0.8444 - val_loss: 0.7230 - val_acc: 0.7956\n",
      "Epoch 129/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5459 - acc: 0.8393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 04:40:19.867380 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.8448 - acc: 0.7702\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.5445 - acc: 0.8399 - val_loss: 0.8369 - val_acc: 0.7702\n",
      "Epoch 130/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5802 - acc: 0.8305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 04:46:44.990541 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 169s 58ms/sample - loss: 0.7637 - acc: 0.7708\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.5808 - acc: 0.8305 - val_loss: 0.8397 - val_acc: 0.7708\n",
      "Epoch 131/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5924 - acc: 0.8253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 04:53:20.238854 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 0.7830 - acc: 0.7706\n",
      "183/183 [==============================] - 392s 2s/step - loss: 0.5917 - acc: 0.8255 - val_loss: 0.8135 - val_acc: 0.7706\n",
      "Epoch 1/1000\n",
      "Epoch 132/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5904 - acc: 0.8278"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 04:59:47.172885 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.8022 - acc: 0.7860\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.5899 - acc: 0.8280 - val_loss: 0.7938 - val_acc: 0.7860\n",
      "Epoch 133/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5190 - acc: 0.8466"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 05:06:10.397722 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 0.6783 - acc: 0.8066\n",
      "Epoch 1/1000\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.5183 - acc: 0.8468 - val_loss: 0.6799 - val_acc: 0.8066\n",
      "Epoch 134/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5851 - acc: 0.8270"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 05:12:38.764938 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 170s 58ms/sample - loss: 0.6982 - acc: 0.7932\n",
      "183/183 [==============================] - 391s 2s/step - loss: 0.5848 - acc: 0.8271 - val_loss: 0.7237 - val_acc: 0.7932\n",
      "Epoch 135/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5306 - acc: 0.8408"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 05:19:15.062936 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.6990 - acc: 0.8109\n",
      "\n",
      "183/183 [==============================] - 391s 2s/step - loss: 0.5300 - acc: 0.8412 - val_loss: 0.6532 - val_acc: 0.8109\n",
      "Epoch 136/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5514 - acc: 0.8358"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 05:25:44.381130 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.0119 - acc: 0.7557\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.5504 - acc: 0.8361 - val_loss: 0.9626 - val_acc: 0.7557\n",
      "Epoch 1/1000\n",
      "Epoch 137/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4919 - acc: 0.8507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 05:32:07.112407 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.6730 - acc: 0.7968\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.4905 - acc: 0.8512 - val_loss: 0.7413 - val_acc: 0.7968\n",
      "Epoch 138/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4896 - acc: 0.8547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 05:38:30.450458 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8878 - acc: 0.7812\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.4896 - acc: 0.8547 - val_loss: 0.8121 - val_acc: 0.7812\n",
      "Epoch 1/1000\n",
      "Epoch 139/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5119 - acc: 0.8511"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 05:44:53.969579 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 158s 54ms/sample - loss: 0.7218 - acc: 0.7797\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.5123 - acc: 0.8509 - val_loss: 0.7953 - val_acc: 0.7797\n",
      "Epoch 140/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5628 - acc: 0.8331"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 05:51:13.520461 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.7659 - acc: 0.7959\n",
      "183/183 [==============================] - 385s 2s/step - loss: 0.5619 - acc: 0.8334 - val_loss: 0.7580 - val_acc: 0.7959\n",
      "Epoch 141/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4987 - acc: 0.8530"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 05:57:37.813580 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.6298 - acc: 0.8153\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.4987 - acc: 0.8530 - val_loss: 0.6431 - val_acc: 0.8153\n",
      "Epoch 142/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5415 - acc: 0.8393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 06:04:01.331450 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 0.6527 - acc: 0.8023\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.5400 - acc: 0.8398 - val_loss: 0.6787 - val_acc: 0.8023\n",
      "Epoch 1/1000\n",
      "Epoch 143/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4930 - acc: 0.8511"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 06:10:20.380920 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 0.7573 - acc: 0.7679\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.4925 - acc: 0.8512 - val_loss: 0.8670 - val_acc: 0.7679\n",
      "Epoch 144/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4926 - acc: 0.8519"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 06:16:56.824642 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.6084 - acc: 0.8050\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.4914 - acc: 0.8522 - val_loss: 0.6773 - val_acc: 0.8050\n",
      "Epoch 1/1000\n",
      "Epoch 145/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4454 - acc: 0.8662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 06:23:23.222250 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 58ms/sample - loss: 0.6503 - acc: 0.7979\n",
      "183/183 [==============================] - 394s 2s/step - loss: 0.4457 - acc: 0.8662 - val_loss: 0.7137 - val_acc: 0.7979\n",
      "Epoch 1/1000\n",
      "Epoch 146/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4391 - acc: 0.8692"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 06:29:56.693889 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.6646 - acc: 0.8049\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.4402 - acc: 0.8688 - val_loss: 0.7372 - val_acc: 0.8049\n",
      "Epoch 1/1000\n",
      "Epoch 147/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4800 - acc: 0.8533"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 06:36:17.928858 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 1.0902 - acc: 0.6749\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.4793 - acc: 0.8535 - val_loss: 1.0980 - val_acc: 0.6749\n",
      "Epoch 148/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4932 - acc: 0.8513"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 06:42:44.868538 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.6345 - acc: 0.8023\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.4926 - acc: 0.8515 - val_loss: 0.7051 - val_acc: 0.8023\n",
      "Epoch 149/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4828 - acc: 0.8551"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 06:49:18.235337 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 56ms/sample - loss: 0.6558 - acc: 0.7751\n",
      "183/183 [==============================] - 394s 2s/step - loss: 0.4830 - acc: 0.8549 - val_loss: 0.7847 - val_acc: 0.7751\n",
      "Epoch 150/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4970 - acc: 0.8513"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 06:55:55.364760 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.6592 - acc: 0.8027\n",
      "183/183 [==============================] - 394s 2s/step - loss: 0.4972 - acc: 0.8512 - val_loss: 0.7164 - val_acc: 0.8027\n",
      "Epoch 151/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5125 - acc: 0.8446"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 07:02:31.091136 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 56ms/sample - loss: 0.7837 - acc: 0.7735\n",
      "183/183 [==============================] - 398s 2s/step - loss: 0.5129 - acc: 0.8443 - val_loss: 1.0181 - val_acc: 0.7735\n",
      "Epoch 152/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4571 - acc: 0.8608"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 07:08:54.176480 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.6629 - acc: 0.8125\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.4570 - acc: 0.8608 - val_loss: 0.6692 - val_acc: 0.8125\n",
      "Epoch 1/1000\n",
      "Epoch 153/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4700 - acc: 0.8558"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 07:15:15.956899 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 172s 59ms/sample - loss: 0.8760 - acc: 0.7622\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.4694 - acc: 0.8559 - val_loss: 1.0345 - val_acc: 0.7622\n",
      "Epoch 1/1000\n",
      "Epoch 154/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4390 - acc: 0.8643"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 07:21:49.726276 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.8008 - acc: 0.7921\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.4401 - acc: 0.8641 - val_loss: 0.7842 - val_acc: 0.7921\n",
      "Epoch 155/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4822 - acc: 0.8549"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 07:28:10.971022 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 177s 60ms/sample - loss: 0.6603 - acc: 0.8051\n",
      "183/183 [==============================] - 397s 2s/step - loss: 0.4819 - acc: 0.8549 - val_loss: 0.6988 - val_acc: 0.8051\n",
      "\n",
      "Epoch 156/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4364 - acc: 0.8656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 07:34:49.887153 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 56ms/sample - loss: 0.8004 - acc: 0.7750\n",
      "183/183 [==============================] - 385s 2s/step - loss: 0.4355 - acc: 0.8660 - val_loss: 1.0468 - val_acc: 0.7750\n",
      "Epoch 157/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4210 - acc: 0.8707"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 07:41:12.994388 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 0.6477 - acc: 0.7958\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.4197 - acc: 0.8711 - val_loss: 0.7064 - val_acc: 0.7958\n",
      "Epoch 1/1000\n",
      "Epoch 158/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4787 - acc: 0.8559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 07:47:34.149859 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 170s 58ms/sample - loss: 0.6517 - acc: 0.8123\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.4786 - acc: 0.8559 - val_loss: 0.6514 - val_acc: 0.8123\n",
      "Epoch 1/1000\n",
      "Epoch 159/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.5317 - acc: 0.8391"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 07:54:12.362196 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.6575 - acc: 0.7930\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.5339 - acc: 0.8387 - val_loss: 0.7682 - val_acc: 0.7930\n",
      "Epoch 160/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4942 - acc: 0.8537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 08:00:34.228761 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 0.7412 - acc: 0.7887\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.4945 - acc: 0.8536 - val_loss: 0.8902 - val_acc: 0.7887\n",
      "Epoch 1/1000\n",
      "Epoch 161/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4446 - acc: 0.8641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 08:06:59.775235 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 0.5579 - acc: 0.8212\n",
      "183/183 [==============================] - 396s 2s/step - loss: 0.4441 - acc: 0.8642 - val_loss: 0.6343 - val_acc: 0.8212\n",
      "Epoch 162/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4689 - acc: 0.8556"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 08:13:37.788219 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.6765 - acc: 0.7852\n",
      "183/183 [==============================] - 385s 2s/step - loss: 0.4679 - acc: 0.8560 - val_loss: 0.7644 - val_acc: 0.7852\n",
      "Epoch 163/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3978 - acc: 0.8808"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 08:19:59.689780 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.6282 - acc: 0.8191\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.3970 - acc: 0.8810 - val_loss: 0.6915 - val_acc: 0.8191\n",
      "Epoch 164/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3894 - acc: 0.8804"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 08:26:19.771673 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.6084 - acc: 0.8218\n",
      "Epoch 1/1000\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.3883 - acc: 0.8807 - val_loss: 0.6034 - val_acc: 0.8218\n",
      "Epoch 165/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4210 - acc: 0.8724"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 08:32:46.105519 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 0.6245 - acc: 0.8154\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.4206 - acc: 0.8725 - val_loss: 0.6342 - val_acc: 0.8154\n",
      "Epoch 166/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4202 - acc: 0.8733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 08:39:05.724335 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 165s 57ms/sample - loss: 0.6557 - acc: 0.8004\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.4191 - acc: 0.8737 - val_loss: 0.6833 - val_acc: 0.8004\n",
      "Epoch 167/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3901 - acc: 0.8802"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 08:45:33.784672 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 56ms/sample - loss: 0.8712 - acc: 0.7871\n",
      "183/183 [==============================] - 385s 2s/step - loss: 0.3915 - acc: 0.8798 - val_loss: 1.0581 - val_acc: 0.7871\n",
      "Epoch 168/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4273 - acc: 0.8714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 08:51:57.012288 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.5971 - acc: 0.8201\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.4263 - acc: 0.8717 - val_loss: 0.6385 - val_acc: 0.8201\n",
      "Epoch 1/1000\n",
      "Epoch 169/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4256 - acc: 0.8713"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 08:58:22.029937 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 1.8563 - acc: 0.7426\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.4258 - acc: 0.8711 - val_loss: 1.7593 - val_acc: 0.7426\n",
      "Epoch 170/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4041 - acc: 0.8758"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 09:04:59.328946 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 0.7370 - acc: 0.7875\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.4031 - acc: 0.8761 - val_loss: 0.8048 - val_acc: 0.7875\n",
      "Epoch 171/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4202 - acc: 0.8722"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 09:11:33.637780 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 57ms/sample - loss: 0.5933 - acc: 0.8252\n",
      "183/183 [==============================] - 403s 2s/step - loss: 0.4190 - acc: 0.8725 - val_loss: 0.6218 - val_acc: 0.8252\n",
      "Epoch 172/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4162 - acc: 0.8733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 09:18:14.185380 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.6570 - acc: 0.8121\n",
      "183/183 [==============================] - 396s 2s/step - loss: 0.4157 - acc: 0.8735 - val_loss: 0.7054 - val_acc: 0.8121\n",
      "Epoch 1/1000\n",
      "Epoch 173/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3723 - acc: 0.8887"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 09:24:44.839833 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.6540 - acc: 0.8210\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.3721 - acc: 0.8888 - val_loss: 0.7127 - val_acc: 0.8210\n",
      "Epoch 174/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4096 - acc: 0.8742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 09:31:13.007074 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 170s 58ms/sample - loss: 0.6980 - acc: 0.8125\n",
      "183/183 [==============================] - 398s 2s/step - loss: 0.4095 - acc: 0.8742 - val_loss: 0.7432 - val_acc: 0.8125\n",
      "Epoch 175/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3933 - acc: 0.8827"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 09:37:43.631133 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 57ms/sample - loss: 0.8385 - acc: 0.7972\n",
      "183/183 [==============================] - 388s 2s/step - loss: 0.3949 - acc: 0.8821 - val_loss: 0.9776 - val_acc: 0.7972\n",
      "Epoch 176/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3865 - acc: 0.8827"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 09:44:13.659905 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 0.8182 - acc: 0.7894\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.3869 - acc: 0.8825 - val_loss: 1.0832 - val_acc: 0.7894\n",
      "Epoch 177/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3395 - acc: 0.8979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 09:50:37.394496 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 57ms/sample - loss: 0.6508 - acc: 0.8177\n",
      "183/183 [==============================] - 388s 2s/step - loss: 0.3405 - acc: 0.8975 - val_loss: 0.7200 - val_acc: 0.8177\n",
      "Epoch 178/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.4573 - acc: 0.8591"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 09:57:11.443291 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.6757 - acc: 0.7965\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.4569 - acc: 0.8592 - val_loss: 0.7331 - val_acc: 0.7965\n",
      "Epoch 179/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3893 - acc: 0.8774"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 10:03:42.733251 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 178s 61ms/sample - loss: 0.6010 - acc: 0.8145\n",
      "183/183 [==============================] - 409s 2s/step - loss: 0.3891 - acc: 0.8775 - val_loss: 0.6146 - val_acc: 0.8145\n",
      "Epoch 1/1000\n",
      "Epoch 180/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3758 - acc: 0.8850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 10:10:22.429943 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.9340 - acc: 0.7661\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.3755 - acc: 0.8853 - val_loss: 1.2927 - val_acc: 0.7661\n",
      "Epoch 181/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3860 - acc: 0.8823"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 10:16:44.843568 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 0.6419 - acc: 0.8316\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.3855 - acc: 0.8825 - val_loss: 0.6187 - val_acc: 0.8316\n",
      "Epoch 182/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3534 - acc: 0.8912"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 10:23:11.744173 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.6608 - acc: 0.8082\n",
      "183/183 [==============================] - 388s 2s/step - loss: 0.3538 - acc: 0.8911 - val_loss: 0.7490 - val_acc: 0.8082\n",
      "Epoch 183/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3702 - acc: 0.8885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 10:29:35.316637 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.7076 - acc: 0.7948\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.3704 - acc: 0.8885 - val_loss: 0.8937 - val_acc: 0.7948\n",
      "Epoch 184/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3858 - acc: 0.8846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 10:36:00.240935 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 172s 59ms/sample - loss: 0.6332 - acc: 0.8086\n",
      "183/183 [==============================] - 396s 2s/step - loss: 0.3856 - acc: 0.8846 - val_loss: 0.7684 - val_acc: 0.8086\n",
      "Epoch 185/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3162 - acc: 0.9037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 10:42:31.018990 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 196s 67ms/sample - loss: 0.6885 - acc: 0.8071\n",
      "183/183 [==============================] - 415s 2s/step - loss: 0.3186 - acc: 0.9029 - val_loss: 0.7801 - val_acc: 0.8071\n",
      "Epoch 186/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3316 - acc: 0.8960"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 10:49:32.346305 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 165s 56ms/sample - loss: 0.5677 - acc: 0.8333\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.3315 - acc: 0.8960 - val_loss: 0.5687 - val_acc: 0.8333\n",
      "Epoch 187/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3629 - acc: 0.8874"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 10:56:08.577999 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 165s 57ms/sample - loss: 0.8186 - acc: 0.8070\n",
      "183/183 [==============================] - 395s 2s/step - loss: 0.3644 - acc: 0.8871 - val_loss: 0.9958 - val_acc: 0.8070\n",
      "Epoch 188/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3353 - acc: 0.8957"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 11:02:38.198827 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 182s 62ms/sample - loss: 0.6110 - acc: 0.8347\n",
      "183/183 [==============================] - 406s 2s/step - loss: 0.3362 - acc: 0.8955 - val_loss: 0.6770 - val_acc: 0.8347\n",
      "Epoch 1/1000\n",
      "Epoch 189/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3375 - acc: 0.8983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 11:09:29.907309 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 56ms/sample - loss: 0.6664 - acc: 0.7989\n",
      "183/183 [==============================] - 392s 2s/step - loss: 0.3410 - acc: 0.8974 - val_loss: 0.7904 - val_acc: 0.7989\n",
      "Epoch 190/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3850 - acc: 0.8813"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 11:16:04.027663 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 183s 63ms/sample - loss: 1.6129 - acc: 0.8102\n",
      "183/183 [==============================] - 415s 2s/step - loss: 0.3854 - acc: 0.8813 - val_loss: 0.7940 - val_acc: 0.8102\n",
      "Epoch 191/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3749 - acc: 0.8863"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 11:22:53.710130 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 190s 65ms/sample - loss: 0.8084 - acc: 0.7563\n",
      "183/183 [==============================] - 417s 2s/step - loss: 0.3751 - acc: 0.8862 - val_loss: 0.9625 - val_acc: 0.7563\n",
      "Epoch 192/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3611 - acc: 0.8877"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 11:29:43.369246 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 175s 60ms/sample - loss: 0.5404 - acc: 0.8399\n",
      "183/183 [==============================] - 394s 2s/step - loss: 0.3603 - acc: 0.8879 - val_loss: 0.6074 - val_acc: 0.8399\n",
      "Epoch 193/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3071 - acc: 0.9047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 11:36:19.793662 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 179s 61ms/sample - loss: 0.5373 - acc: 0.8256\n",
      "183/183 [==============================] - 400s 2s/step - loss: 0.3063 - acc: 0.9050 - val_loss: 0.6184 - val_acc: 0.8256\n",
      "Epoch 194/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2982 - acc: 0.9067"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 11:42:58.141286 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 0.6663 - acc: 0.8120\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.2990 - acc: 0.9064 - val_loss: 0.8719 - val_acc: 0.8120\n",
      "Epoch 195/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3288 - acc: 0.8974"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 11:49:29.093989 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 170s 58ms/sample - loss: 0.5533 - acc: 0.8359\n",
      "183/183 [==============================] - 395s 2s/step - loss: 0.3287 - acc: 0.8973 - val_loss: 0.6502 - val_acc: 0.8359\n",
      "Epoch 196/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3406 - acc: 0.8936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 11:56:08.722923 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 56ms/sample - loss: 0.5787 - acc: 0.8384\n",
      "183/183 [==============================] - 392s 2s/step - loss: 0.3408 - acc: 0.8935 - val_loss: 0.6189 - val_acc: 0.8384\n",
      "Epoch 197/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3445 - acc: 0.8915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 12:02:39.101232 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 0.6045 - acc: 0.8369\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.3443 - acc: 0.8916 - val_loss: 0.6980 - val_acc: 0.8369\n",
      "Epoch 198/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3300 - acc: 0.8963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 12:08:57.831920 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.6575 - acc: 0.8218\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.3293 - acc: 0.8966 - val_loss: 0.7133 - val_acc: 0.8218\n",
      "Epoch 199/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3487 - acc: 0.8909"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 12:15:18.723392 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.7108 - acc: 0.8000\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.3503 - acc: 0.8905 - val_loss: 0.9350 - val_acc: 0.8000\n",
      "Epoch 200/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3357 - acc: 0.8976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 12:21:45.549861 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 0.6558 - acc: 0.8197\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.3359 - acc: 0.8975 - val_loss: 0.8627 - val_acc: 0.8197\n",
      "Epoch 1/1000\n",
      "Epoch 201/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3125 - acc: 0.9000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 12:28:03.610251 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 0.5387 - acc: 0.8313\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.3130 - acc: 0.8998 - val_loss: 0.6974 - val_acc: 0.8313\n",
      "Epoch 1/1000\n",
      "Epoch 202/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2860 - acc: 0.9106"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 12:34:26.490207 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 174s 60ms/sample - loss: 0.6620 - acc: 0.8200\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.2860 - acc: 0.9106 - val_loss: 0.8821 - val_acc: 0.8200\n",
      "Epoch 1/1000\n",
      "Epoch 203/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3329 - acc: 0.8955"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 12:41:00.105929 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.6261 - acc: 0.8315\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.3339 - acc: 0.8953 - val_loss: 0.7535 - val_acc: 0.8315\n",
      "Epoch 1/1000\n",
      "Epoch 204/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3365 - acc: 0.8938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 12:47:21.410993 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.4850 - acc: 0.8497\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.3354 - acc: 0.8942 - val_loss: 0.5437 - val_acc: 0.8497\n",
      "Epoch 205/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3376 - acc: 0.8948"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 12:53:45.370680 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 0.6879 - acc: 0.8090\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.3372 - acc: 0.8949 - val_loss: 0.8664 - val_acc: 0.8090\n",
      "Epoch 1/1000\n",
      "Epoch 206/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3236 - acc: 0.8993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 13:00:06.269505 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.7280 - acc: 0.8161\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.3230 - acc: 0.8996 - val_loss: 1.0190 - val_acc: 0.8161\n",
      "Epoch 207/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3253 - acc: 0.8979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 13:06:27.360493 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 169s 58ms/sample - loss: 1.0037 - acc: 0.7904\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.3247 - acc: 0.8981 - val_loss: 1.5200 - val_acc: 0.7904\n",
      "Epoch 208/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2951 - acc: 0.9064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 13:13:04.471001 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.0358 - acc: 0.7746\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.2971 - acc: 0.9059 - val_loss: 1.3785 - val_acc: 0.7746\n",
      "Epoch 1/1000\n",
      "Epoch 209/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2514 - acc: 0.9199"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 13:19:33.066739 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.9465 - acc: 0.7970\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.2513 - acc: 0.9200 - val_loss: 1.3349 - val_acc: 0.7970\n",
      "Epoch 210/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2790 - acc: 0.9121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 13:25:53.009485 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.7538 - acc: 0.8165\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.2803 - acc: 0.9115 - val_loss: 1.0099 - val_acc: 0.8165\n",
      "Epoch 1/1000\n",
      "Epoch 211/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3170 - acc: 0.9012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 13:32:14.134908 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.5634 - acc: 0.8388\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.3184 - acc: 0.9007 - val_loss: 0.6767 - val_acc: 0.8388\n",
      "Epoch 1/1000\n",
      "Epoch 212/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3276 - acc: 0.8965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 13:38:34.290906 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 57ms/sample - loss: 0.7240 - acc: 0.8239\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.3270 - acc: 0.8967 - val_loss: 0.8714 - val_acc: 0.8239\n",
      "Epoch 213/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3153 - acc: 0.9001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 13:45:01.940329 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 0.7899 - acc: 0.8203\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.3154 - acc: 0.9000 - val_loss: 1.0742 - val_acc: 0.8203\n",
      "Epoch 214/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3069 - acc: 0.9043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 13:51:25.686025 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.6067 - acc: 0.8360\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.3060 - acc: 0.9046 - val_loss: 0.7799 - val_acc: 0.8360\n",
      "Epoch 215/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3111 - acc: 0.9013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 13:57:44.323460 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 1.7363 - acc: 0.8079\n",
      "183/183 [==============================] - 378s 2s/step - loss: 0.3106 - acc: 0.9015 - val_loss: 1.1238 - val_acc: 0.8079\n",
      "Epoch 216/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3110 - acc: 0.9018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 14:04:09.263938 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 177s 61ms/sample - loss: 0.8104 - acc: 0.8024\n",
      "183/183 [==============================] - 403s 2s/step - loss: 0.3109 - acc: 0.9018 - val_loss: 1.1083 - val_acc: 0.8024\n",
      "Epoch 217/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2917 - acc: 0.9088"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 14:10:51.698900 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 0.8327 - acc: 0.8197\n",
      "183/183 [==============================] - 392s 2s/step - loss: 0.2914 - acc: 0.9088 - val_loss: 1.1595 - val_acc: 0.8197\n",
      "Epoch 218/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2689 - acc: 0.9152"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 14:17:25.924883 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 0.6306 - acc: 0.8368\n",
      "183/183 [==============================] - 388s 2s/step - loss: 0.2682 - acc: 0.9154 - val_loss: 0.8064 - val_acc: 0.8368\n",
      "Epoch 219/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3121 - acc: 0.8998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 14:23:49.735411 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.8905 - acc: 0.7990\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.3121 - acc: 0.8997 - val_loss: 1.1540 - val_acc: 0.7990\n",
      "Epoch 220/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2842 - acc: 0.9104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 14:30:14.772985 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 1.1387 - acc: 0.7744\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.2838 - acc: 0.9106 - val_loss: 1.7253 - val_acc: 0.7744\n",
      "Epoch 221/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2830 - acc: 0.9122"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 14:36:39.456127 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 170s 58ms/sample - loss: 1.0965 - acc: 0.7844\n",
      "183/183 [==============================] - 392s 2s/step - loss: 0.2838 - acc: 0.9118 - val_loss: 1.7380 - val_acc: 0.7844\n",
      "Epoch 222/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2823 - acc: 0.9128"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 14:43:12.846347 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 0.8652 - acc: 0.8110\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.2818 - acc: 0.9130 - val_loss: 1.1344 - val_acc: 0.8110\n",
      "Epoch 1/1000\n",
      "Epoch 223/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2710 - acc: 0.9150"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 14:49:32.198786 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 0.7512 - acc: 0.8341\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.2707 - acc: 0.9151 - val_loss: 0.8489 - val_acc: 0.8341\n",
      "Epoch 224/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2642 - acc: 0.9157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 14:56:00.102716 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 0.5714 - acc: 0.8496\n",
      "183/183 [==============================] - 388s 2s/step - loss: 0.2637 - acc: 0.9159 - val_loss: 0.6799 - val_acc: 0.8496\n",
      "Epoch 225/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2530 - acc: 0.9202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 15:02:29.507554 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.6477 - acc: 0.8464\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.2535 - acc: 0.9199 - val_loss: 0.7735 - val_acc: 0.8464\n",
      "Epoch 226/1000\n",
      "Epoch 1/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2897 - acc: 0.9107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 15:08:55.917949 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.7780 - acc: 0.8180\n",
      "183/183 [==============================] - 388s 2s/step - loss: 0.2903 - acc: 0.9104 - val_loss: 0.8558 - val_acc: 0.8180\n",
      "Epoch 1/1000\n",
      "Epoch 227/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2653 - acc: 0.9168"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 15:15:23.119815 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 170s 58ms/sample - loss: 0.7069 - acc: 0.8317\n",
      "183/183 [==============================] - 396s 2s/step - loss: 0.2656 - acc: 0.9167 - val_loss: 0.9446 - val_acc: 0.8317\n",
      "Epoch 228/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2888 - acc: 0.9091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 15:22:01.127124 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 174s 59ms/sample - loss: 0.6768 - acc: 0.8330\n",
      "183/183 [==============================] - 401s 2s/step - loss: 0.2883 - acc: 0.9092 - val_loss: 0.8579 - val_acc: 0.8330\n",
      "Epoch 229/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2759 - acc: 0.9120"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 15:28:40.117323 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 172s 59ms/sample - loss: 0.6887 - acc: 0.8253\n",
      "183/183 [==============================] - 397s 2s/step - loss: 0.2759 - acc: 0.9120 - val_loss: 0.9292 - val_acc: 0.8253\n",
      "Epoch 230/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.3121 - acc: 0.9023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 15:35:14.292827 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.7919 - acc: 0.8215\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.3119 - acc: 0.9022 - val_loss: 1.0157 - val_acc: 0.8215\n",
      "Epoch 1/1000Epoch 231/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2934 - acc: 0.9057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 15:41:34.649425 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 1.1010 - acc: 0.7826\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.2937 - acc: 0.9057 - val_loss: 1.5542 - val_acc: 0.7826\n",
      "Epoch 232/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2779 - acc: 0.9112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 15:47:53.172520 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.7640 - acc: 0.8267\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.2780 - acc: 0.9112 - val_loss: 1.0414 - val_acc: 0.8267\n",
      "Epoch 1/1000\n",
      "Epoch 233/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2520 - acc: 0.9203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 15:54:15.232598 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 57ms/sample - loss: 0.6172 - acc: 0.8450\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.2516 - acc: 0.9204 - val_loss: 0.7192 - val_acc: 0.8450\n",
      "Epoch 234/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2266 - acc: 0.9271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 16:00:54.104389 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 174s 59ms/sample - loss: 0.5811 - acc: 0.8543\n",
      "183/183 [==============================] - 404s 2s/step - loss: 0.2270 - acc: 0.9269 - val_loss: 0.7167 - val_acc: 0.8543\n",
      "Epoch 235/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2535 - acc: 0.9194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 16:07:38.077850 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 58ms/sample - loss: 0.7676 - acc: 0.8298\n",
      "183/183 [==============================] - 399s 2s/step - loss: 0.2538 - acc: 0.9192 - val_loss: 1.0791 - val_acc: 0.8298\n",
      "\n",
      "Epoch 236/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2296 - acc: 0.9250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 16:14:14.987953 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 170s 58ms/sample - loss: 0.9761 - acc: 0.8078\n",
      "183/183 [==============================] - 398s 2s/step - loss: 0.2306 - acc: 0.9248 - val_loss: 1.3664 - val_acc: 0.8078\n",
      "Epoch 237/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2440 - acc: 0.9210"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 16:20:51.025935 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.2203 - acc: 0.7713\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.2436 - acc: 0.9211 - val_loss: 2.0016 - val_acc: 0.7713\n",
      "Epoch 238/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2375 - acc: 0.9251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 16:27:18.813021 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.7433 - acc: 0.8363\n",
      "183/183 [==============================] - 388s 2s/step - loss: 0.2374 - acc: 0.9251 - val_loss: 0.9413 - val_acc: 0.8363\n",
      "Epoch 1/1000\n",
      "Epoch 239/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2509 - acc: 0.9194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 16:33:40.795736 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8683 - acc: 0.8138\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.2514 - acc: 0.9193 - val_loss: 1.3289 - val_acc: 0.8138\n",
      "Epoch 240/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2525 - acc: 0.9195"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 16:40:01.487643 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 0.8336 - acc: 0.8222\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.2534 - acc: 0.9191 - val_loss: 1.2527 - val_acc: 0.8222\n",
      "Epoch 241/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2354 - acc: 0.9249"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 16:46:29.732806 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8347 - acc: 0.8203\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.2359 - acc: 0.9247 - val_loss: 1.1321 - val_acc: 0.8203\n",
      "Epoch 242/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2171 - acc: 0.9293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 16:52:49.774121 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 169s 58ms/sample - loss: 0.6397 - acc: 0.8576\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.2178 - acc: 0.9291 - val_loss: 0.7540 - val_acc: 0.8576\n",
      "Epoch 243/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2172 - acc: 0.9304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 16:59:21.681784 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.6357 - acc: 0.8455\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.2170 - acc: 0.9304 - val_loss: 0.8144 - val_acc: 0.8455\n",
      "Epoch 244/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2316 - acc: 0.9252"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 17:05:42.486604 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 158s 54ms/sample - loss: 0.7380 - acc: 0.8316\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.2312 - acc: 0.9254 - val_loss: 0.9446 - val_acc: 0.8316\n",
      "Epoch 245/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2321 - acc: 0.9249"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 17:12:01.179311 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.9369 - acc: 0.8137\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.2316 - acc: 0.9250 - val_loss: 1.3577 - val_acc: 0.8137\n",
      "Epoch 246/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2334 - acc: 0.9227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 17:18:22.477230 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.9222 - acc: 0.8112\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.2335 - acc: 0.9226 - val_loss: 1.2946 - val_acc: 0.8112\n",
      "Epoch 247/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2687 - acc: 0.9133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 17:24:42.797357 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 0.7517 - acc: 0.8332\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.2687 - acc: 0.9132 - val_loss: 0.9942 - val_acc: 0.8332\n",
      "Epoch 248/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2588 - acc: 0.9171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 17:31:01.791836 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 56ms/sample - loss: 0.6479 - acc: 0.8382\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.2580 - acc: 0.9174 - val_loss: 0.8724 - val_acc: 0.8382\n",
      "Epoch 1/1000\n",
      "Epoch 249/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2199 - acc: 0.9283"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 17:37:30.955571 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.7126 - acc: 0.8360\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.2205 - acc: 0.9280 - val_loss: 0.9272 - val_acc: 0.8360\n",
      "Epoch 250/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2290 - acc: 0.9260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 17:44:01.125085 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 0.9354 - acc: 0.8079\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.2285 - acc: 0.9261 - val_loss: 1.4399 - val_acc: 0.8079\n",
      "Epoch 251/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2231 - acc: 0.9277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 17:50:22.606942 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.6144 - acc: 0.8583\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.2232 - acc: 0.9276 - val_loss: 0.7220 - val_acc: 0.8583\n",
      "Epoch 252/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2278 - acc: 0.9272"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 17:56:53.618947 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 56ms/sample - loss: 0.5431 - acc: 0.8619\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.2279 - acc: 0.9271 - val_loss: 0.6480 - val_acc: 0.8619\n",
      "Epoch 253/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2302 - acc: 0.9243"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 18:03:20.134589 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.9775 - acc: 0.8067\n",
      "183/183 [==============================] - 385s 2s/step - loss: 0.2299 - acc: 0.9244 - val_loss: 1.4774 - val_acc: 0.8067\n",
      "Epoch 254/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2448 - acc: 0.9212"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 18:09:45.074984 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 174s 60ms/sample - loss: 1.1999 - acc: 0.7858\n",
      "183/183 [==============================] - 399s 2s/step - loss: 0.2446 - acc: 0.9213 - val_loss: 1.7602 - val_acc: 0.7858\n",
      "Epoch 255/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2288 - acc: 0.9254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 18:16:22.533104 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 0.9060 - acc: 0.8140\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.2290 - acc: 0.9254 - val_loss: 1.3787 - val_acc: 0.8140\n",
      "Epoch 256/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2328 - acc: 0.9249"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 18:22:59.935566 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.7557 - acc: 0.8297\n",
      "183/183 [==============================] - 391s 2s/step - loss: 0.2323 - acc: 0.9251 - val_loss: 1.1068 - val_acc: 0.8297\n",
      "Epoch 257/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2305 - acc: 0.9261"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 18:29:27.724380 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.5997 - acc: 0.8474\n",
      "183/183 [==============================] - 392s 2s/step - loss: 0.2307 - acc: 0.9259 - val_loss: 0.7509 - val_acc: 0.8474\n",
      "\n",
      "Epoch 258/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2135 - acc: 0.9297"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 18:35:54.668366 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 165s 57ms/sample - loss: 0.6438 - acc: 0.8411\n",
      "183/183 [==============================] - 388s 2s/step - loss: 0.2132 - acc: 0.9298 - val_loss: 0.8489 - val_acc: 0.8411\n",
      "\n",
      "Epoch 259/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2454 - acc: 0.9197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 18:42:22.418977 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 0.5704 - acc: 0.8552\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.2454 - acc: 0.9198 - val_loss: 0.6402 - val_acc: 0.8552\n",
      "Epoch 260/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2019 - acc: 0.9345"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 18:48:41.359031 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 0.5143 - acc: 0.8532\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.2015 - acc: 0.9346 - val_loss: 0.6029 - val_acc: 0.8532\n",
      "Epoch 1/1000\n",
      "Epoch 261/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2053 - acc: 0.9334"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 18:55:09.641509 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 169s 58ms/sample - loss: 1.5444 - acc: 0.8553\n",
      "183/183 [==============================] - 391s 2s/step - loss: 0.2058 - acc: 0.9333 - val_loss: 0.6527 - val_acc: 0.8553\n",
      "Epoch 262/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2542 - acc: 0.9175"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 19:01:38.687281 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 1.5547 - acc: 0.8488\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.2533 - acc: 0.9179 - val_loss: 0.7961 - val_acc: 0.8488\n",
      "Epoch 263/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2355 - acc: 0.9233"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 19:08:06.536550 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 0.5413 - acc: 0.8514\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.2349 - acc: 0.9235 - val_loss: 0.7758 - val_acc: 0.8514\n",
      "Epoch 264/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2283 - acc: 0.9264"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 19:14:32.997864 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.7478 - acc: 0.8334\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.2280 - acc: 0.9264 - val_loss: 1.0818 - val_acc: 0.8334\n",
      "Epoch 265/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1810 - acc: 0.9411"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 19:20:53.755619 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 176s 60ms/sample - loss: 1.8164 - acc: 0.8245\n",
      "183/183 [==============================] - 396s 2s/step - loss: 0.1808 - acc: 0.9411 - val_loss: 1.2762 - val_acc: 0.8245\n",
      "Epoch 266/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1909 - acc: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 19:27:30.162268 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 0.6407 - acc: 0.8541\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.1907 - acc: 0.9376 - val_loss: 0.7706 - val_acc: 0.8541\n",
      "Epoch 267/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1905 - acc: 0.9372"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 19:33:56.489785 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 1.5037 - acc: 0.8568\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.1904 - acc: 0.9372 - val_loss: 0.7457 - val_acc: 0.8568\n",
      "Epoch 268/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1907 - acc: 0.9373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 19:40:27.297585 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 175s 60ms/sample - loss: 1.5208 - acc: 0.8497\n",
      "183/183 [==============================] - 400s 2s/step - loss: 0.1902 - acc: 0.9375 - val_loss: 0.8410 - val_acc: 0.8497\n",
      "Epoch 1/1000\n",
      "Epoch 269/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2055 - acc: 0.9319"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 19:47:10.059796 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 1.6055 - acc: 0.8475\n",
      "183/183 [==============================] - 391s 2s/step - loss: 0.2058 - acc: 0.9318 - val_loss: 0.7403 - val_acc: 0.8475\n",
      "Epoch 270/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2100 - acc: 0.9296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 19:53:37.321466 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 56ms/sample - loss: 1.5705 - acc: 0.8472\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.2100 - acc: 0.9295 - val_loss: 0.8477 - val_acc: 0.8472\n",
      "Epoch 1/1000\n",
      "Epoch 271/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2054 - acc: 0.9320"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 20:00:08.043102 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.6451 - acc: 0.8467\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.2060 - acc: 0.9319 - val_loss: 0.8795 - val_acc: 0.8467\n",
      "Epoch 1/1000\n",
      "Epoch 272/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1946 - acc: 0.9348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 20:06:31.563823 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 1.6931 - acc: 0.8314\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.1953 - acc: 0.9346 - val_loss: 1.1298 - val_acc: 0.8314\n",
      "Epoch 273/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1729 - acc: 0.9414"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 20:13:03.314553 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 1.6173 - acc: 0.8448\n",
      "183/183 [==============================] - 388s 2s/step - loss: 0.1727 - acc: 0.9415 - val_loss: 0.9921 - val_acc: 0.8448\n",
      "Epoch 274/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1851 - acc: 0.9388"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 20:19:35.878149 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 165s 57ms/sample - loss: 1.6386 - acc: 0.8438\n",
      "183/183 [==============================] - 395s 2s/step - loss: 0.1848 - acc: 0.9389 - val_loss: 1.0319 - val_acc: 0.8438\n",
      "Epoch 275/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1930 - acc: 0.9359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 20:26:02.835920 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 174s 60ms/sample - loss: 0.9759 - acc: 0.8192\n",
      "183/183 [==============================] - 396s 2s/step - loss: 0.1934 - acc: 0.9358 - val_loss: 1.3070 - val_acc: 0.8192\n",
      "Epoch 276/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1965 - acc: 0.9349"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 20:32:37.541601 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 0.7245 - acc: 0.8365\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.1973 - acc: 0.9346 - val_loss: 0.9629 - val_acc: 0.8365\n",
      "Epoch 1/1000\n",
      "Epoch 277/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2016 - acc: 0.9327"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 20:38:55.972195 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 0.8058 - acc: 0.8347\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.2017 - acc: 0.9327 - val_loss: 1.1760 - val_acc: 0.8347\n",
      "Epoch 278/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1928 - acc: 0.9364"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 20:45:15.334285 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 175s 60ms/sample - loss: 0.5010 - acc: 0.8690\n",
      "183/183 [==============================] - 395s 2s/step - loss: 0.1927 - acc: 0.9364 - val_loss: 0.5841 - val_acc: 0.8690\n",
      "\n",
      "Epoch 279/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1840 - acc: 0.9394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 20:51:57.308107 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 165s 56ms/sample - loss: 0.4765 - acc: 0.8757\n",
      "183/183 [==============================] - 392s 2s/step - loss: 0.1840 - acc: 0.9394 - val_loss: 0.5530 - val_acc: 0.8757\n",
      "Epoch 280/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2102 - acc: 0.9309"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 20:58:24.712719 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 170s 58ms/sample - loss: 0.6640 - acc: 0.8589\n",
      "183/183 [==============================] - 392s 2s/step - loss: 0.2100 - acc: 0.9309 - val_loss: 0.8068 - val_acc: 0.8589\n",
      "Epoch 1/1000\n",
      "Epoch 281/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1874 - acc: 0.9368"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 21:04:55.237498 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 175s 60ms/sample - loss: 0.8298 - acc: 0.8354\n",
      "183/183 [==============================] - 396s 2s/step - loss: 0.1869 - acc: 0.9370 - val_loss: 1.1468 - val_acc: 0.8354\n",
      "Epoch 1/1000\n",
      "Epoch 282/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2009 - acc: 0.9326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 21:11:33.940414 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 2.2300 - acc: 0.7721\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.2008 - acc: 0.9326 - val_loss: 2.1083 - val_acc: 0.7721\n",
      "Epoch 1/1000\n",
      "Epoch 283/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2227 - acc: 0.9290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 21:17:55.621096 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 58ms/sample - loss: 0.8810 - acc: 0.8256\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.2230 - acc: 0.9289 - val_loss: 1.1861 - val_acc: 0.8256\n",
      "Epoch 284/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2234 - acc: 0.9258"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 21:24:26.130707 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 169s 58ms/sample - loss: 1.8754 - acc: 0.8230\n",
      "183/183 [==============================] - 392s 2s/step - loss: 0.2236 - acc: 0.9258 - val_loss: 1.3620 - val_acc: 0.8230\n",
      "Epoch 1/1000\n",
      "Epoch 285/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2234 - acc: 0.9267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 21:31:04.269164 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 174s 60ms/sample - loss: 1.3523 - acc: 0.7761\n",
      "183/183 [==============================] - 403s 2s/step - loss: 0.2233 - acc: 0.9267 - val_loss: 2.1348 - val_acc: 0.7761\n",
      "Epoch 286/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2041 - acc: 0.9326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 21:37:44.584495 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 172s 59ms/sample - loss: 1.9402 - acc: 0.7423\n",
      "183/183 [==============================] - 399s 2s/step - loss: 0.2039 - acc: 0.9327 - val_loss: 2.6394 - val_acc: 0.7423\n",
      "Epoch 287/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1935 - acc: 0.9372"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 21:44:22.456014 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.0031 - acc: 0.8132\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.1931 - acc: 0.9373 - val_loss: 1.5191 - val_acc: 0.8132\n",
      "Epoch 1/1000Epoch 288/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2091 - acc: 0.9308"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 21:50:42.981293 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.9369 - acc: 0.8211\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.2086 - acc: 0.9310 - val_loss: 1.3468 - val_acc: 0.8211\n",
      "Epoch 1/1000\n",
      "Epoch 289/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1774 - acc: 0.9406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 21:57:05.324432 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 56ms/sample - loss: 0.8421 - acc: 0.8316\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.1771 - acc: 0.9407 - val_loss: 1.2592 - val_acc: 0.8316\n",
      "Epoch 290/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1887 - acc: 0.9369"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 22:03:27.945844 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 55ms/sample - loss: 1.1167 - acc: 0.8049\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.1885 - acc: 0.9369 - val_loss: 1.7123 - val_acc: 0.8049\n",
      "Epoch 291/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1893 - acc: 0.9364"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 22:09:50.233427 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.9915 - acc: 0.8078\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.1902 - acc: 0.9362 - val_loss: 1.5898 - val_acc: 0.8078\n",
      "Epoch 292/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1967 - acc: 0.9331"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 22:16:16.865551 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 165s 56ms/sample - loss: 0.7701 - acc: 0.8412\n",
      "183/183 [==============================] - 388s 2s/step - loss: 0.1969 - acc: 0.9331 - val_loss: 1.1158 - val_acc: 0.8412\n",
      "Epoch 293/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1826 - acc: 0.9401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 22:22:48.995731 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 169s 58ms/sample - loss: 0.7554 - acc: 0.8425\n",
      "183/183 [==============================] - 397s 2s/step - loss: 0.1826 - acc: 0.9401 - val_loss: 1.0597 - val_acc: 0.8425\n",
      "Epoch 294/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1955 - acc: 0.9341"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 22:29:21.370461 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8928 - acc: 0.8190\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.1951 - acc: 0.9342 - val_loss: 1.3744 - val_acc: 0.8190\n",
      "Epoch 295/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1967 - acc: 0.9350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 22:35:44.864451 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 57ms/sample - loss: 1.0140 - acc: 0.8057\n",
      "183/183 [==============================] - 391s 2s/step - loss: 0.1964 - acc: 0.9351 - val_loss: 1.5040 - val_acc: 0.8057\n",
      "Epoch 1/1000\n",
      "Epoch 296/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1754 - acc: 0.9413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 22:42:14.058442 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 55ms/sample - loss: 0.6709 - acc: 0.8490\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.1755 - acc: 0.9413 - val_loss: 0.8874 - val_acc: 0.8490\n",
      "Epoch 297/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1743 - acc: 0.9413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 22:48:38.982809 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 0.9090 - acc: 0.8242\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.1743 - acc: 0.9413 - val_loss: 1.3664 - val_acc: 0.8242\n",
      "\n",
      "Epoch 298/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1712 - acc: 0.9416"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 22:54:57.074572 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.9943 - acc: 0.8111\n",
      "183/183 [==============================] - 378s 2s/step - loss: 0.1712 - acc: 0.9416 - val_loss: 1.4594 - val_acc: 0.8111\n",
      "Epoch 299/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1682 - acc: 0.9431"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 23:01:22.953500 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.7276 - acc: 0.8351\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.1684 - acc: 0.9430 - val_loss: 1.1865 - val_acc: 0.8351\n",
      "Epoch 300/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1726 - acc: 0.9421"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 23:07:52.003042 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 55ms/sample - loss: 0.8471 - acc: 0.8343\n",
      "183/183 [==============================] - 391s 2s/step - loss: 0.1724 - acc: 0.9422 - val_loss: 1.2372 - val_acc: 0.8343\n",
      "Epoch 301/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1746 - acc: 0.9435"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 23:14:21.418502 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 165s 57ms/sample - loss: 1.8080 - acc: 0.8294\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.1744 - acc: 0.9436 - val_loss: 1.3333 - val_acc: 0.8294\n",
      "Epoch 302/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1770 - acc: 0.9411"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 23:20:52.790101 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 172s 59ms/sample - loss: 0.7181 - acc: 0.8499\n",
      "183/183 [==============================] - 398s 2s/step - loss: 0.1770 - acc: 0.9411 - val_loss: 0.8837 - val_acc: 0.8499\n",
      "Epoch 1/1000\n",
      "Epoch 303/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1840 - acc: 0.9384"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 23:27:24.000523 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.7403 - acc: 0.8410\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.1845 - acc: 0.9383 - val_loss: 1.0800 - val_acc: 0.8410\n",
      "Epoch 304/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1830 - acc: 0.9382"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 23:33:48.870746 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 165s 57ms/sample - loss: 1.1422 - acc: 0.8124\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.1844 - acc: 0.9378 - val_loss: 1.5318 - val_acc: 0.8124\n",
      "Epoch 305/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1666 - acc: 0.9437"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 23:40:14.897649 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8974 - acc: 0.8327\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.1664 - acc: 0.9438 - val_loss: 1.2993 - val_acc: 0.8327\n",
      "Epoch 306/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1708 - acc: 0.9425"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 23:46:33.522735 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.1013 - acc: 0.8169\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.1704 - acc: 0.9426 - val_loss: 1.6223 - val_acc: 0.8169\n",
      "Epoch 307/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1761 - acc: 0.9402"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 23:52:54.151335 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 171s 59ms/sample - loss: 1.1163 - acc: 0.7989\n",
      "183/183 [==============================] - 392s 2s/step - loss: 0.1761 - acc: 0.9402 - val_loss: 1.7074 - val_acc: 0.7989\n",
      "Epoch 308/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1600 - acc: 0.9463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1126 23:59:38.142503 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.8115 - acc: 0.8344\n",
      "183/183 [==============================] - 394s 2s/step - loss: 0.1597 - acc: 0.9464 - val_loss: 1.2480 - val_acc: 0.8344\n",
      "Epoch 309/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1703 - acc: 0.9432"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 00:06:10.485626 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 176s 60ms/sample - loss: 0.7609 - acc: 0.8396\n",
      "183/183 [==============================] - 407s 2s/step - loss: 0.1701 - acc: 0.9433 - val_loss: 1.0581 - val_acc: 0.8396\n",
      "Epoch 310/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1732 - acc: 0.9416"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 00:12:54.971324 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 165s 56ms/sample - loss: 0.8415 - acc: 0.8340\n",
      "183/183 [==============================] - 394s 2s/step - loss: 0.1734 - acc: 0.9416 - val_loss: 1.3146 - val_acc: 0.8340\n",
      "Epoch 1/1000\n",
      "Epoch 311/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2076 - acc: 0.9309"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 00:19:31.420261 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 176s 60ms/sample - loss: 0.8503 - acc: 0.8329\n",
      "183/183 [==============================] - 407s 2s/step - loss: 0.2075 - acc: 0.9309 - val_loss: 1.2952 - val_acc: 0.8329\n",
      "Epoch 1/1000\n",
      "Epoch 312/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1821 - acc: 0.9384"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 00:26:15.149416 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 58ms/sample - loss: 0.8174 - acc: 0.8412\n",
      "183/183 [==============================] - 397s 2s/step - loss: 0.1819 - acc: 0.9384 - val_loss: 1.1829 - val_acc: 0.8412\n",
      "Epoch 1/1000\n",
      "Epoch 313/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1615 - acc: 0.9450"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 00:32:44.415289 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 158s 54ms/sample - loss: 0.9693 - acc: 0.8200\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.1612 - acc: 0.9452 - val_loss: 1.5077 - val_acc: 0.8200\n",
      "Epoch 314/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1529 - acc: 0.9482"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 00:39:02.675969 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 173s 59ms/sample - loss: 0.7847 - acc: 0.8356\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.1530 - acc: 0.9482 - val_loss: 1.2112 - val_acc: 0.8356\n",
      "Epoch 315/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1600 - acc: 0.9455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 00:45:35.627636 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.1405 - acc: 0.8097\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.1597 - acc: 0.9456 - val_loss: 1.7381 - val_acc: 0.8097\n",
      "Epoch 316/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1651 - acc: 0.9439"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 00:51:54.698656 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 0.9394 - acc: 0.8151\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.1649 - acc: 0.9439 - val_loss: 1.3859 - val_acc: 0.8151\n",
      "Epoch 317/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1904 - acc: 0.9366"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 00:58:21.731816 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 1.0510 - acc: 0.8097\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.1903 - acc: 0.9367 - val_loss: 1.6007 - val_acc: 0.8097\n",
      "Epoch 318/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1885 - acc: 0.9377"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 01:04:43.838128 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.8670 - acc: 0.8230\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.1881 - acc: 0.9378 - val_loss: 1.3085 - val_acc: 0.8230\n",
      "Epoch 319/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1661 - acc: 0.9442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 01:11:04.498001 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 158s 54ms/sample - loss: 0.8109 - acc: 0.8418\n",
      "183/183 [==============================] - 378s 2s/step - loss: 0.1659 - acc: 0.9443 - val_loss: 1.2004 - val_acc: 0.8418\n",
      "Epoch 320/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1650 - acc: 0.9441"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 01:17:29.928092 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 172s 59ms/sample - loss: 0.7133 - acc: 0.8488\n",
      "183/183 [==============================] - 399s 2s/step - loss: 0.1646 - acc: 0.9442 - val_loss: 0.8813 - val_acc: 0.8488\n",
      "Epoch 321/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1726 - acc: 0.9420"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 01:24:07.935829 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 1.3841 - acc: 0.7815\n",
      "183/183 [==============================] - 385s 2s/step - loss: 0.1725 - acc: 0.9420 - val_loss: 2.2014 - val_acc: 0.7815\n",
      "Epoch 1/1000\n",
      "Epoch 322/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1755 - acc: 0.9414"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 01:30:27.957612 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 169s 58ms/sample - loss: 1.0808 - acc: 0.8000\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.1753 - acc: 0.9414 - val_loss: 1.6883 - val_acc: 0.8000\n",
      "Epoch 323/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1549 - acc: 0.9469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 01:36:58.282514 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 1.2485 - acc: 0.7943\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.1548 - acc: 0.9469 - val_loss: 1.8660 - val_acc: 0.7943\n",
      "Epoch 324/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1682 - acc: 0.9427"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 01:43:16.583065 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.8633 - acc: 0.8242\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.1677 - acc: 0.9429 - val_loss: 1.2760 - val_acc: 0.8242\n",
      "Epoch 325/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1675 - acc: 0.9432"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 01:49:41.498762 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 165s 57ms/sample - loss: 0.8074 - acc: 0.8338\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.1673 - acc: 0.9433 - val_loss: 1.1828 - val_acc: 0.8338\n",
      "Epoch 326/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1707 - acc: 0.9422"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 01:56:08.613585 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 171s 59ms/sample - loss: 0.9116 - acc: 0.8227\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.1707 - acc: 0.9421 - val_loss: 1.4035 - val_acc: 0.8227\n",
      "Epoch 327/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1920 - acc: 0.9360"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 02:02:38.414456 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 1.0677 - acc: 0.8007\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.1918 - acc: 0.9361 - val_loss: 1.7406 - val_acc: 0.8007\n",
      "Epoch 328/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1751 - acc: 0.9416"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 02:09:00.028607 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 173s 59ms/sample - loss: 1.0198 - acc: 0.8050\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.1754 - acc: 0.9415 - val_loss: 1.6790 - val_acc: 0.8050\n",
      "Epoch 329/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1494 - acc: 0.9490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 02:15:33.189717 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.5621 - acc: 0.8628\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.1496 - acc: 0.9490 - val_loss: 0.7838 - val_acc: 0.8628\n",
      "Epoch 1/1000\n",
      "Epoch 330/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1607 - acc: 0.9449"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 02:21:51.233750 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 0.6831 - acc: 0.8521\n",
      "183/183 [==============================] - 385s 2s/step - loss: 0.1606 - acc: 0.9450 - val_loss: 1.0252 - val_acc: 0.8521\n",
      "Epoch 331/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1674 - acc: 0.9432"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 02:28:18.791719 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 1.2855 - acc: 0.7758\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.1683 - acc: 0.9428 - val_loss: 2.2059 - val_acc: 0.7758\n",
      "Epoch 332/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1750 - acc: 0.9420"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 02:34:37.625844 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.8743 - acc: 0.8201\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.1755 - acc: 0.9418 - val_loss: 1.2381 - val_acc: 0.8201\n",
      "Epoch 1/1000\n",
      "Epoch 333/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1576 - acc: 0.9467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 02:41:07.175177 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.8650 - acc: 0.8232\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.1576 - acc: 0.9467 - val_loss: 1.3945 - val_acc: 0.8232\n",
      "Epoch 334/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1614 - acc: 0.9450"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 02:47:38.613046 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 1.1225 - acc: 0.8074\n",
      "183/183 [==============================] - 392s 2s/step - loss: 0.1617 - acc: 0.9449 - val_loss: 1.7332 - val_acc: 0.8074\n",
      "Epoch 1/1000\n",
      "Epoch 335/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.2077 - acc: 0.9302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 02:54:03.924061 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.0954 - acc: 0.7996\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.2083 - acc: 0.9302 - val_loss: 1.7617 - val_acc: 0.7996\n",
      "Epoch 336/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1839 - acc: 0.9374"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 03:00:25.074558 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.6881 - acc: 0.8531\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.1834 - acc: 0.9375 - val_loss: 0.9914 - val_acc: 0.8531\n",
      "Epoch 1/1000\n",
      "Epoch 337/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1681 - acc: 0.9425"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 03:06:49.152130 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 158s 54ms/sample - loss: 0.7198 - acc: 0.8550\n",
      "183/183 [==============================] - 378s 2s/step - loss: 0.1680 - acc: 0.9426 - val_loss: 0.9398 - val_acc: 0.8550\n",
      "Epoch 338/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1726 - acc: 0.9397"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 03:13:07.063635 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.0035 - acc: 0.8069\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.1725 - acc: 0.9397 - val_loss: 1.6839 - val_acc: 0.8069\n",
      "Epoch 339/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1547 - acc: 0.9475"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 03:19:26.330995 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 0.8621 - acc: 0.8286\n",
      "183/183 [==============================] - 385s 2s/step - loss: 0.1558 - acc: 0.9472 - val_loss: 1.3612 - val_acc: 0.8286\n",
      "Epoch 340/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1919 - acc: 0.9365"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 03:25:59.118520 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 0.6548 - acc: 0.8593\n",
      "183/183 [==============================] - 394s 2s/step - loss: 0.1918 - acc: 0.9365 - val_loss: 0.8471 - val_acc: 0.8593\n",
      "Epoch 341/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1830 - acc: 0.9388"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 03:32:37.231178 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8358 - acc: 0.8354\n",
      "183/183 [==============================] - 391s 2s/step - loss: 0.1837 - acc: 0.9386 - val_loss: 1.1542 - val_acc: 0.8354\n",
      "Epoch 1/1000\n",
      "Epoch 342/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1722 - acc: 0.9427"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 03:39:07.243353 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 0.7592 - acc: 0.8412\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.1719 - acc: 0.9428 - val_loss: 1.1452 - val_acc: 0.8412\n",
      "Epoch 343/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1548 - acc: 0.9483"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 03:45:32.925572 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.6849 - acc: 0.8493\n",
      "183/183 [==============================] - 388s 2s/step - loss: 0.1547 - acc: 0.9483 - val_loss: 0.9941 - val_acc: 0.8493\n",
      "Epoch 344/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1386 - acc: 0.9536"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 03:51:56.243151 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.5949 - acc: 0.8658\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.1387 - acc: 0.9536 - val_loss: 0.8436 - val_acc: 0.8658\n",
      "Epoch 345/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1410 - acc: 0.9521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 03:58:17.752587 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 55ms/sample - loss: 0.6441 - acc: 0.8610\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.1416 - acc: 0.9519 - val_loss: 0.9085 - val_acc: 0.8610\n",
      "Epoch 346/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1399 - acc: 0.9521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 04:04:48.710134 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 2.0292 - acc: 0.8162\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.1404 - acc: 0.9520 - val_loss: 1.6236 - val_acc: 0.8162\n",
      "Epoch 1/1000\n",
      "Epoch 347/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1653 - acc: 0.9442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 04:11:12.766555 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 171s 59ms/sample - loss: 1.2076 - acc: 0.8012\n",
      "183/183 [==============================] - 395s 2s/step - loss: 0.1650 - acc: 0.9443 - val_loss: 1.8319 - val_acc: 0.8012\n",
      "Epoch 348/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1564 - acc: 0.9463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 04:17:54.921204 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 1.1851 - acc: 0.7968\n",
      "183/183 [==============================] - 397s 2s/step - loss: 0.1565 - acc: 0.9462 - val_loss: 1.7628 - val_acc: 0.7968\n",
      "Epoch 349/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1609 - acc: 0.9446"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 04:24:24.542343 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 0.7588 - acc: 0.8436\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.1609 - acc: 0.9446 - val_loss: 1.1312 - val_acc: 0.8436\n",
      "Epoch 350/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1511 - acc: 0.9485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 04:30:50.875522 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 158s 54ms/sample - loss: 0.8558 - acc: 0.8401\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.1511 - acc: 0.9484 - val_loss: 1.2593 - val_acc: 0.8401\n",
      "Epoch 351/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1642 - acc: 0.9440"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 04:37:09.408408 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8948 - acc: 0.8329\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.1641 - acc: 0.9441 - val_loss: 1.3285 - val_acc: 0.8329\n",
      "Epoch 1/1000\n",
      "Epoch 352/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1379 - acc: 0.9527"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 04:43:38.773653 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 175s 60ms/sample - loss: 1.0872 - acc: 0.8129\n",
      "183/183 [==============================] - 405s 2s/step - loss: 0.1377 - acc: 0.9528 - val_loss: 1.7017 - val_acc: 0.8129\n",
      "Epoch 353/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1440 - acc: 0.9514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 04:50:16.890076 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 165s 56ms/sample - loss: 0.8427 - acc: 0.8398\n",
      "183/183 [==============================] - 388s 2s/step - loss: 0.1438 - acc: 0.9515 - val_loss: 1.2250 - val_acc: 0.8398\n",
      "Epoch 354/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1465 - acc: 0.9500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 04:56:43.107562 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 158s 54ms/sample - loss: 0.8652 - acc: 0.8320\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.1466 - acc: 0.9499 - val_loss: 1.3381 - val_acc: 0.8320\n",
      "Epoch 355/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1549 - acc: 0.9470"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 05:02:59.511762 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.9593 - acc: 0.8255\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.1552 - acc: 0.9468 - val_loss: 1.4649 - val_acc: 0.8255\n",
      "Epoch 356/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1450 - acc: 0.9507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 05:09:18.501484 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 0.9830 - acc: 0.8223\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.1452 - acc: 0.9506 - val_loss: 1.5503 - val_acc: 0.8223\n",
      "Epoch 357/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1519 - acc: 0.9480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 05:15:45.425242 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 0.6293 - acc: 0.8515\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.1519 - acc: 0.9480 - val_loss: 0.8050 - val_acc: 0.8515\n",
      "Epoch 358/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1532 - acc: 0.9474"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 05:22:07.416236 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.8229 - acc: 0.8388\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.1539 - acc: 0.9472 - val_loss: 1.1758 - val_acc: 0.8388\n",
      "Epoch 359/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1690 - acc: 0.9422"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 05:28:31.382689 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 1.0948 - acc: 0.8035\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.1692 - acc: 0.9421 - val_loss: 1.7519 - val_acc: 0.8035\n",
      "Epoch 1/1000\n",
      "Epoch 360/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1682 - acc: 0.9432"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 05:35:06.485002 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 1.1794 - acc: 0.7992\n",
      "183/183 [==============================] - 394s 2s/step - loss: 0.1679 - acc: 0.9433 - val_loss: 1.8481 - val_acc: 0.7992\n",
      "Epoch 361/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1411 - acc: 0.9517"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 05:41:34.789484 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.1901 - acc: 0.7982\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.1410 - acc: 0.9517 - val_loss: 1.8410 - val_acc: 0.7982\n",
      "Epoch 1/1000\n",
      "Epoch 362/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1345 - acc: 0.9534"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 05:47:55.459599 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 170s 58ms/sample - loss: 1.3964 - acc: 0.7939\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.1343 - acc: 0.9535 - val_loss: 1.9828 - val_acc: 0.7939\n",
      "Epoch 363/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1396 - acc: 0.9525"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 05:54:35.670887 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 172s 59ms/sample - loss: 1.0979 - acc: 0.8089\n",
      "183/183 [==============================] - 402s 2s/step - loss: 0.1393 - acc: 0.9525 - val_loss: 1.6427 - val_acc: 0.8089\n",
      "Epoch 364/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1455 - acc: 0.9497"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 06:01:13.309740 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.3207 - acc: 0.7866\n",
      "183/183 [==============================] - 386s 2s/step - loss: 0.1456 - acc: 0.9497 - val_loss: 2.0489 - val_acc: 0.7866\n",
      "Epoch 365/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1359 - acc: 0.9530"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 06:07:43.507558 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 1.2502 - acc: 0.7965\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.1362 - acc: 0.9529 - val_loss: 1.9669 - val_acc: 0.7965\n",
      "Epoch 366/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1604 - acc: 0.9454"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 06:14:12.940926 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 172s 59ms/sample - loss: 1.1925 - acc: 0.7965\n",
      "183/183 [==============================] - 399s 2s/step - loss: 0.1609 - acc: 0.9453 - val_loss: 1.8695 - val_acc: 0.7965\n",
      "Epoch 367/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1624 - acc: 0.9446"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 06:20:45.337932 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.9293 - acc: 0.8180\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.1622 - acc: 0.9446 - val_loss: 1.4634 - val_acc: 0.8180\n",
      "Epoch 368/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1381 - acc: 0.9519"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 06:27:09.408455 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 167s 57ms/sample - loss: 1.1027 - acc: 0.8064\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.1379 - acc: 0.9519 - val_loss: 1.7753 - val_acc: 0.8064\n",
      "Epoch 369/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1321 - acc: 0.9538"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 06:33:43.546458 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.2526 - acc: 0.7866\n",
      "183/183 [==============================] - 387s 2s/step - loss: 0.1320 - acc: 0.9539 - val_loss: 2.1040 - val_acc: 0.7866\n",
      "Epoch 370/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1368 - acc: 0.9534"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 06:40:03.833231 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.5587 - acc: 0.8695\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.1368 - acc: 0.9534 - val_loss: 0.7809 - val_acc: 0.8695\n",
      "Epoch 371/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1422 - acc: 0.9510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 06:46:23.363561 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 1.2362 - acc: 0.7908\n",
      "183/183 [==============================] - 385s 2s/step - loss: 0.1422 - acc: 0.9510 - val_loss: 2.0428 - val_acc: 0.7908\n",
      "Epoch 372/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1314 - acc: 0.9545"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 06:52:49.420954 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.9245 - acc: 0.8255\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.1311 - acc: 0.9546 - val_loss: 1.4784 - val_acc: 0.8255\n",
      "\n",
      "Epoch 373/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1508 - acc: 0.9491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 06:59:16.635903 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 1.5652 - acc: 0.7653\n",
      "183/183 [==============================] - 384s 2s/step - loss: 0.1503 - acc: 0.9493 - val_loss: 2.5059 - val_acc: 0.7653\n",
      "Epoch 374/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1584 - acc: 0.9459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 07:05:36.661788 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 0.9905 - acc: 0.8188\n",
      "183/183 [==============================] - 378s 2s/step - loss: 0.1583 - acc: 0.9459 - val_loss: 1.5343 - val_acc: 0.8188\n",
      "Epoch 1/1000\n",
      "Epoch 375/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1568 - acc: 0.9460"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 07:11:54.584647 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 1.1350 - acc: 0.8059\n",
      "183/183 [==============================] - 379s 2s/step - loss: 0.1566 - acc: 0.9461 - val_loss: 1.7915 - val_acc: 0.8059\n",
      "Epoch 376/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1450 - acc: 0.9497"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 07:18:12.725188 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 55ms/sample - loss: 0.6628 - acc: 0.8592\n",
      "183/183 [==============================] - 378s 2s/step - loss: 0.1448 - acc: 0.9499 - val_loss: 0.9607 - val_acc: 0.8592\n",
      "Epoch 377/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1322 - acc: 0.9538"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 07:24:30.323105 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 1.0463 - acc: 0.8192\n",
      "183/183 [==============================] - 377s 2s/step - loss: 0.1320 - acc: 0.9539 - val_loss: 1.6066 - val_acc: 0.8192\n",
      "Epoch 378/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1512 - acc: 0.9480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 07:30:47.797685 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 166s 57ms/sample - loss: 1.1147 - acc: 0.8109\n",
      "183/183 [==============================] - 385s 2s/step - loss: 0.1507 - acc: 0.9482 - val_loss: 1.6970 - val_acc: 0.8109\n",
      "Epoch 379/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1361 - acc: 0.9526"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 07:37:15.594372 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.9861 - acc: 0.8228\n",
      "183/183 [==============================] - 382s 2s/step - loss: 0.1358 - acc: 0.9527 - val_loss: 1.5910 - val_acc: 0.8228\n",
      "Epoch 380/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1267 - acc: 0.9560"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 07:43:36.925952 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.9021 - acc: 0.8393\n",
      "183/183 [==============================] - 381s 2s/step - loss: 0.1265 - acc: 0.9561 - val_loss: 1.3102 - val_acc: 0.8393\n",
      "Epoch 1/1000\n",
      "Epoch 381/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1312 - acc: 0.9549"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 07:49:59.191365 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.8112 - acc: 0.8477\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.1319 - acc: 0.9547 - val_loss: 1.1784 - val_acc: 0.8477\n",
      "Epoch 1/1000\n",
      "Epoch 382/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1354 - acc: 0.9526"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 07:56:27.927411 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 162s 55ms/sample - loss: 0.7917 - acc: 0.8410\n",
      "183/183 [==============================] - 390s 2s/step - loss: 0.1351 - acc: 0.9527 - val_loss: 1.1526 - val_acc: 0.8410\n",
      "Epoch 383/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1472 - acc: 0.9491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 08:02:55.969006 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 168s 57ms/sample - loss: 0.9063 - acc: 0.8366\n",
      "183/183 [==============================] - 393s 2s/step - loss: 0.1469 - acc: 0.9492 - val_loss: 1.3393 - val_acc: 0.8366\n",
      "Epoch 1/1000\n",
      "Epoch 384/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1336 - acc: 0.9543"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 08:09:31.569859 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.8717 - acc: 0.8373\n",
      "183/183 [==============================] - 388s 2s/step - loss: 0.1333 - acc: 0.9544 - val_loss: 1.3438 - val_acc: 0.8373\n",
      "Epoch 385/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1204 - acc: 0.9582"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 08:15:51.903165 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 163s 56ms/sample - loss: 1.0101 - acc: 0.8198\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.1203 - acc: 0.9582 - val_loss: 1.5774 - val_acc: 0.8198\n",
      "Epoch 386/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1285 - acc: 0.9552"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 08:22:13.767817 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 170s 58ms/sample - loss: 0.9770 - acc: 0.8262\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.1288 - acc: 0.9551 - val_loss: 1.4566 - val_acc: 0.8262\n",
      "Epoch 1/1000\n",
      "Epoch 387/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1436 - acc: 0.9509"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 08:28:51.674724 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 161s 55ms/sample - loss: 0.8784 - acc: 0.8368\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.1436 - acc: 0.9509 - val_loss: 1.2755 - val_acc: 0.8368\n",
      "Epoch 388/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1317 - acc: 0.9542"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 08:35:12.830812 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 0.7571 - acc: 0.8543\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.1315 - acc: 0.9543 - val_loss: 1.0521 - val_acc: 0.8543\n",
      "Epoch 389/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1324 - acc: 0.9539"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 08:41:37.701871 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 164s 56ms/sample - loss: 0.8952 - acc: 0.8365\n",
      "183/183 [==============================] - 389s 2s/step - loss: 0.1324 - acc: 0.9539 - val_loss: 1.3268 - val_acc: 0.8365\n",
      "\n",
      "Epoch 390/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1377 - acc: 0.9516"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 08:48:04.558052 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 160s 55ms/sample - loss: 1.2461 - acc: 0.8013\n",
      "183/183 [==============================] - 383s 2s/step - loss: 0.1377 - acc: 0.9516 - val_loss: 1.9327 - val_acc: 0.8013\n",
      "Epoch 391/1000\n",
      "182/183 [============================>.] - ETA: 1s - loss: 0.1411 - acc: 0.9507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 08:54:26.135348 140736185191632 training_generator.py:413] Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2920/183 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 159s 54ms/sample - loss: 0.8668 - acc: 0.8347\n",
      "183/183 [==============================] - 380s 2s/step - loss: 0.1408 - acc: 0.9508 - val_loss: 1.3578 - val_acc: 0.8347\n",
      "Epoch 392/1000\n",
      "  4/183 [..............................] - ETA: 3:45 - loss: 0.1928 - acc: 0.9321"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-6:\n",
      "Process Keras_worker_ForkPoolWorker-5:\n",
      "Process Keras_worker_ForkPoolWorker-3:\n",
      "Process Keras_worker_ForkPoolWorker-8:\n",
      "Process Keras_worker_ForkPoolWorker-7:\n",
      "Process Keras_worker_ForkPoolWorker-4:\n",
      "Process Keras_worker_ForkPoolWorker-2:\n",
      "Process Keras_worker_ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 832, in next_sample\n",
      "    return six.next(_SHARED_SEQUENCES[uid])\n",
      "  File \"/stg318/User/taniguchi-j/DeepLab_v3plus/data_gen.py\", line 16, in make_data_gen\n",
      "    x,y = data_augment(x,y)\n",
      "  File \"/stg318/User/taniguchi-j/DeepLab_v3plus/data_augment.py\", line 38, in data_augment\n",
      "    auged = aug(image=images[i,:,:,:],mask=masks[i,:,:,:])\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/albumentations/core/composition.py\", line 176, in __call__\n",
      "    data = t(force_apply=force_apply, **data)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/albumentations/core/composition.py\", line 221, in __call__\n",
      "    data = t(force_apply=True, **data)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/albumentations/imgaug/transforms.py\", line 38, in __call__\n",
      "    return super(BasicIAATransform, self).__call__(**kwargs)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/albumentations/core/transforms_interface.py\", line 87, in __call__\n",
      "    return self.apply_with_params(params, **kwargs)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/albumentations/core/transforms_interface.py\", line 100, in apply_with_params\n",
      "    res[key] = target_function(arg, **dict(params, **target_dependencies))\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/albumentations/core/transforms_interface.py\", line 223, in apply_to_mask\n",
      "    return self.apply(img, **{k: cv2.INTER_NEAREST if k == \"interpolation\" else v for k, v in params.items()})\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/albumentations/imgaug/transforms.py\", line 46, in apply\n",
      "    return deterministic_processor.augment_image(img)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/imgaug/augmenters/meta.py\", line 571, in augment_image\n",
      "    return self.augment_images([image], hooks=hooks)[0]\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/imgaug/augmenters/meta.py\", line 695, in augment_images\n",
      "    hooks=hooks\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/imgaug/augmenters/geometric.py\", line 2088, in _augment_images\n",
      "    output_shape=images[i].shape\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/skimage/transform/_warps.py\", line 906, in warp\n",
      "    coords = warp_coords(coord_map, output_shape)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/skimage/transform/_warps.py\", line 613, in warp_coords\n",
      "    tf_coords = coord_map(tf_coords)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/skimage/transform/_warps.py\", line 897, in coord_map\n",
      "    return inverse_map(*args, **map_args)\n",
      "  File \"/home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/skimage/transform/_geometric.py\", line 890, in __call__\n",
      "    simplex = self._tesselation.find_simplex(coords)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0f82556aa7bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#hist = model.fit_generator(data_gen, validation_data=(valid_x, valid_y), epochs=par.n_epochs, steps_per_epoch=par.n_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#hist = model.fit_generator(data_gen, epochs=par.n_epochs, steps_per_epoch=par.n_batch, workers=8, use_multiprocessing=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    970\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    971\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    973\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    974\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[0;32m~/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_BiasAddGrad\u001b[0;34m(op, received_grad)\u001b[0m\n\u001b[1;32m    348\u001b[0m   return (received_grad,\n\u001b[1;32m    349\u001b[0m           gen_nn_ops.bias_add_grad(\n\u001b[0;32m--> 350\u001b[0;31m               out_backprop=received_grad, data_format=data_format))\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add_grad\u001b[0;34m(out_backprop, data_format, name)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;34m\"BiasAddGrad\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \"data_format\", data_format)\n\u001b[0m\u001b[1;32m    828\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#hist = model.fit_generator(data_gen, validation_data=(valid_x, valid_y), epochs=par.n_epochs, steps_per_epoch=par.n_batch)\n",
    "hist = model.fit_generator(data_gen, validation_data=(valid_x, valid_y), epochs=par.n_epochs, steps_per_epoch=par.n_batch, workers=8, use_multiprocessing=True, callbacks=[cp_cb])\n",
    "#hist = model.fit_generator(data_gen, epochs=par.n_epochs, steps_per_epoch=par.n_batch, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2e0ed8ea9a6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(hist.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(hist.history[\"acc\"], label=\"acc\")\n",
    "plt.plot(hist.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.legend()\n",
    "plt.savefig(\"saved_model/losscurve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"test2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
