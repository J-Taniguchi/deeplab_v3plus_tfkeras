{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabv3plus_dir=\"./src\"\n",
    "sys.path.append(deeplabv3plus_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(visible_device_list=\"0\", allow_growth=True)\n",
    "config = tf.compat.v1.ConfigProto(gpu_options = gpu_options)\n",
    "tf.compat.v1.enable_eager_execution(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import deeplab_v3plus_transfer\n",
    "#from image_utils import make_x_from_image_paths,make_y_from_image_paths,convert_y_to_image_array\n",
    "from data_gen import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_gen' from './src/data_gen.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(sys.modules['data_gen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"unfreeze_xception_transfer\"\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories = 21\n",
    "image_size = (512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_img_dir = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/SegmentationClass\"\n",
    "img_dir = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/JPEGImages\"\n",
    "train_set_path = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt\"\n",
    "valid_set_path = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt\"\n",
    "\n",
    "with open(train_set_path) as f:\n",
    "    train_img_names = f.read().split(\"\\n\")[:-1]\n",
    "with open(valid_set_path) as f:\n",
    "    valid_img_names = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "img_paths = [os.path.join(img_dir,train_img_names[i]) + \".jpg\" for i in range(len(train_img_names))]\n",
    "seg_img_paths = [os.path.join(seg_img_dir,train_img_names[i]) + \".png\" for i in range(len(train_img_names))]\n",
    "\n",
    "valid_x_paths = [os.path.join(img_dir,valid_img_names[i]) + \".jpg\" for i in range(len(valid_img_names))]\n",
    "valid_y_paths = [os.path.join(seg_img_dir,valid_img_names[i]) + \".png\" for i in range(len(valid_img_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "n_epochs=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = DataGenerator(n_categories, image_size, batch_size, img_paths    , seg_img_paths, augmentation=True )\n",
    "valid_data_gen = DataGenerator(n_categories, image_size, batch_size, valid_x_paths, valid_y_paths, augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1128 12:58:38.140564 140735578197200 deprecation.py:323] From /home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('./saved_model_transfer/final_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.categorical_crossentropy\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=opt, loss=loss_function, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"xception_deeplab-v3plus\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 255, 255, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 255, 255, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 255, 255, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 253, 253, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 253, 253, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 253, 253, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 253, 253, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 253, 253, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 253, 253, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 253, 253, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 253, 253, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 127, 127, 128 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 127, 127, 128 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 127, 127, 128 512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 127, 127, 128 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 127, 127, 128 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 127, 127, 256 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 127, 127, 256 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 127, 127, 256 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 127, 127, 256 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 127, 127, 256 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 64, 64, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 64, 64, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 64, 64, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 64, 64, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 64, 64, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 64, 64, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 64, 64, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 32, 32, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 32, 32, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 32, 32, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 32, 32, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 32, 32, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 32, 32, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 32, 32, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 32, 32, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 32, 32, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 32, 32, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 32, 32, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 32, 32, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 32, 32, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 32, 32, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 32, 32, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 32, 32, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 32, 32, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 32, 32, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 32, 32, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 32, 32, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 32, 32, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 32, 32, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 32, 32, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 32, 32, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 32, 32, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 32, 32, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 32, 32, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 32, 32, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 32, 32, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 32, 32, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 32, 32, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 32, 32, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 32, 32, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 32, 32, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 32, 32, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 32, 32, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 32, 32, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 32, 32, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 32, 32, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 32, 32, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 32, 32, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 32, 32, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 32, 32, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 32, 32, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 32, 32, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 32, 32, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 32, 32, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 32, 32, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 32, 32, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 1024) 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 16, 16, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 1024) 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 16, 16, 1536) 1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 16, 16, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 16, 16, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 16, 16, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 16, 16, 2048) 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 16, 16, 2048) 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "aspp2_sc1 (DepthwiseConv2D)     (None, 16, 16, 2048) 20480       block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "aspp3_sc1 (DepthwiseConv2D)     (None, 16, 16, 2048) 20480       block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "aspp4_sc1 (DepthwiseConv2D)     (None, 16, 16, 2048) 20480       block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "aspp2_sc-bn1 (BatchNormalizatio (None, 16, 16, 2048) 8192        aspp2_sc1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp3_sc-bn1 (BatchNormalizatio (None, 16, 16, 2048) 8192        aspp3_sc1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp4_sc-bn1 (BatchNormalizatio (None, 16, 16, 2048) 8192        aspp4_sc1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL (None, 1, 1, 2048)   0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "aspp2_sc-act1 (Activation)      (None, 16, 16, 2048) 0           aspp2_sc-bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aspp3_sc-act1 (Activation)      (None, 16, 16, 2048) 0           aspp3_sc-bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aspp4_sc-act1 (Activation)      (None, 16, 16, 2048) 0           aspp4_sc-bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aspp5_cv1 (Conv2D)              (None, 1, 1, 256)    524544      tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "aspp1_cv1 (Conv2D)              (None, 16, 16, 256)  524544      block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "aspp2_cv1 (Conv2D)              (None, 16, 16, 256)  524544      aspp2_sc-act1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aspp3_cv1 (Conv2D)              (None, 16, 16, 256)  524544      aspp3_sc-act1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aspp4_cv1 (Conv2D)              (None, 16, 16, 256)  524544      aspp4_sc-act1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aspp5_bn1 (BatchNormalization)  (None, 1, 1, 256)    1024        aspp5_cv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp1_bn1 (BatchNormalization)  (None, 16, 16, 256)  1024        aspp1_cv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp2_cv-bn1 (BatchNormalizatio (None, 16, 16, 256)  1024        aspp2_cv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp3_cv-bn1 (BatchNormalizatio (None, 16, 16, 256)  1024        aspp3_cv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp4_cv-bn1 (BatchNormalizatio (None, 16, 16, 256)  1024        aspp4_cv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp5_act1 (Activation)         (None, 1, 1, 256)    0           aspp5_bn1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp1_act1 (Activation)         (None, 16, 16, 256)  0           aspp1_bn1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp2_cv-act1 (Activation)      (None, 16, 16, 256)  0           aspp2_cv-bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aspp3_cv-act1 (Activation)      (None, 16, 16, 256)  0           aspp3_cv-bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aspp4_cv-act1 (Activation)      (None, 16, 16, 256)  0           aspp4_cv-bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aspp5_upsampling (UpSampling2D) (None, 16, 16, 256)  0           aspp5_act1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ASPP (Concatenate)              (None, 16, 16, 1280) 0           aspp1_act1[0][0]                 \n",
      "                                                                 aspp2_cv-act1[0][0]              \n",
      "                                                                 aspp3_cv-act1[0][0]              \n",
      "                                                                 aspp4_cv-act1[0][0]              \n",
      "                                                                 aspp5_upsampling[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "ASPP_cv1 (Conv2D)               (None, 16, 16, 256)  327936      ASPP[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dec1_cv1 (Conv2D)               (None, 64, 64, 256)  65792       block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "ASPP_bn1 (BatchNormalization)   (None, 16, 16, 256)  1024        ASPP_cv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec1_bn1 (BatchNormalization)   (None, 64, 64, 256)  1024        dec1_cv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ASPP_act1 (Activation)          (None, 16, 16, 256)  0           ASPP_bn1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec1_act1 (Activation)          (None, 64, 64, 256)  0           dec1_bn1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ASPP_upsample_4 (UpSampling2D)  (None, 64, 64, 256)  0           ASPP_act1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_concat (Concatenate)        (None, 64, 64, 512)  0           dec1_act1[0][0]                  \n",
      "                                                                 ASPP_upsample_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dec1_sc2 (DepthwiseConv2D)      (None, 64, 64, 512)  5120        dec_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec1_sc-bn2 (BatchNormalization (None, 64, 64, 512)  2048        dec1_sc2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec1_sc-act2 (Activation)       (None, 64, 64, 512)  0           dec1_sc-bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec1_cv2 (Conv2D)               (None, 64, 64, 256)  131328      dec1_sc-act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dec1_cv-bn2 (BatchNormalization (None, 64, 64, 256)  1024        dec1_cv2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec1_cv-act2 (Activation)       (None, 64, 64, 256)  0           dec1_cv-bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_upsample_1 (UpSampling2D)   (None, 256, 256, 256 0           dec1_cv-act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dec2_sc1 (DepthwiseConv2D)      (None, 256, 256, 256 2560        dec_upsample_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dec2_sc-bn1 (BatchNormalization (None, 256, 256, 256 1024        dec2_sc1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec2_sc-act1 (Activation)       (None, 256, 256, 256 0           dec2_sc-bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec2_cv1 (Conv2D)               (None, 256, 256, 21) 5397        dec2_sc-act1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dec2_cv-bn1 (BatchNormalization (None, 256, 256, 21) 84          dec2_cv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 256, 256, 21) 0           dec2_cv-bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_upsample_2 (UpSampling2D)   (None, 512, 512, 21) 0           softmax[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,119,697\n",
      "Trainable params: 24,047,207\n",
      "Non-trainable params: 72,490\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(out_dir,'{epoch:06d}.h5')\n",
    "cp_cb = keras.callbacks.ModelCheckpoint(filepath, \n",
    "                                        monitor='val_loss', \n",
    "                                        verbose=0, \n",
    "                                        save_best_only=True, \n",
    "                                        save_weights_only=False, \n",
    "                                        mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.7861 - acc: 0.8022Epoch 1/300\n",
      "92/92 [==============================] - 245s 3s/step - loss: 0.7860 - acc: 0.8021 - val_loss: 1.2411 - val_acc: 0.7771\n",
      "Epoch 2/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.5738 - acc: 0.8274Epoch 1/300\n",
      "92/92 [==============================] - 171s 2s/step - loss: 0.5721 - acc: 0.8279 - val_loss: 1.0285 - val_acc: 0.7848\n",
      "Epoch 3/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.4842 - acc: 0.8439Epoch 1/300\n",
      "92/92 [==============================] - 175s 2s/step - loss: 0.4840 - acc: 0.8440 - val_loss: 1.0482 - val_acc: 0.7465\n",
      "Epoch 4/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.3544 - acc: 0.8816Epoch 1/300\n",
      "92/92 [==============================] - 178s 2s/step - loss: 0.3557 - acc: 0.8813 - val_loss: 0.7301 - val_acc: 0.7993\n",
      "Epoch 5/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.3284 - acc: 0.8862Epoch 1/300\n",
      "92/92 [==============================] - 166s 2s/step - loss: 0.3276 - acc: 0.8865 - val_loss: 0.6044 - val_acc: 0.8328\n",
      "Epoch 6/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.2642 - acc: 0.9089Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.5521 - acc: 0.8484Epoch 1/300\n",
      "92/92 [==============================] - 175s 2s/step - loss: 0.2642 - acc: 0.9089 - val_loss: 0.5637 - val_acc: 0.8475\n",
      "Epoch 7/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.2146 - acc: 0.9239Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.4956 - acc: 0.8612Epoch 1/300\n",
      "92/92 [==============================] - 202s 2s/step - loss: 0.2153 - acc: 0.9236 - val_loss: 0.4997 - val_acc: 0.8610\n",
      "Epoch 8/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.2072 - acc: 0.9267Epoch 1/300\n",
      "92/92 [==============================] - 173s 2s/step - loss: 0.2097 - acc: 0.9260 - val_loss: 0.6180 - val_acc: 0.8416\n",
      "Epoch 9/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.2072 - acc: 0.9256Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.6116 - acc: 0.8461Epoch 1/300\n",
      "92/92 [==============================] - 172s 2s/step - loss: 0.2075 - acc: 0.9255 - val_loss: 0.6148 - val_acc: 0.8458\n",
      "Epoch 10/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.2144 - acc: 0.9241Epoch 1/300\n",
      "92/92 [==============================] - 183s 2s/step - loss: 0.2147 - acc: 0.9241 - val_loss: 0.6932 - val_acc: 0.8369\n",
      "Epoch 11/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.2529 - acc: 0.9115Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.7699 - acc: 0.8193Epoch 1/300\n",
      "92/92 [==============================] - 169s 2s/step - loss: 0.2524 - acc: 0.9117 - val_loss: 0.7794 - val_acc: 0.8184\n",
      "Epoch 12/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.2167 - acc: 0.9243Epoch 1/300\n",
      "92/92 [==============================] - 178s 2s/step - loss: 0.2183 - acc: 0.9237 - val_loss: 0.5627 - val_acc: 0.8474\n",
      "Epoch 13/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1970 - acc: 0.9304Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.5145 - acc: 0.8649Epoch 1/300\n",
      "92/92 [==============================] - 182s 2s/step - loss: 0.1966 - acc: 0.9306 - val_loss: 0.5203 - val_acc: 0.8645\n",
      "Epoch 14/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1971 - acc: 0.9293Epoch 1/300\n",
      "92/92 [==============================] - 174s 2s/step - loss: 0.1968 - acc: 0.9294 - val_loss: 0.6884 - val_acc: 0.8330\n",
      "Epoch 15/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.2024 - acc: 0.9276Epoch 1/300\n",
      "92/92 [==============================] - 173s 2s/step - loss: 0.2024 - acc: 0.9276 - val_loss: 0.5996 - val_acc: 0.8519\n",
      "Epoch 16/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1829 - acc: 0.9346Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.7019 - acc: 0.8276Epoch 1/300\n",
      "92/92 [==============================] - 174s 2s/step - loss: 0.1826 - acc: 0.9347 - val_loss: 0.7074 - val_acc: 0.8272\n",
      "Epoch 17/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1744 - acc: 0.9368Epoch 1/300\n",
      "92/92 [==============================] - 175s 2s/step - loss: 0.1742 - acc: 0.9369 - val_loss: 0.5364 - val_acc: 0.8616\n",
      "Epoch 18/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1447 - acc: 0.9468Epoch 1/300\n",
      "92/92 [==============================] - 173s 2s/step - loss: 0.1447 - acc: 0.9468 - val_loss: 0.4838 - val_acc: 0.8679\n",
      "Epoch 19/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1400 - acc: 0.9482Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.6029 - acc: 0.8600Epoch 1/300\n",
      "92/92 [==============================] - 173s 2s/step - loss: 0.1407 - acc: 0.9480 - val_loss: 0.6131 - val_acc: 0.8591\n",
      "Epoch 20/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1363 - acc: 0.9495Epoch 1/300\n",
      "92/92 [==============================] - 183s 2s/step - loss: 0.1359 - acc: 0.9497 - val_loss: 0.5003 - val_acc: 0.8727\n",
      "Epoch 21/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1313 - acc: 0.9512Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.5177 - acc: 0.8665Epoch 1/300\n",
      "92/92 [==============================] - 176s 2s/step - loss: 0.1312 - acc: 0.9512 - val_loss: 0.5260 - val_acc: 0.8661\n",
      "Epoch 22/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1734 - acc: 0.9387Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.9881 - acc: 0.7921Epoch 1/300\n",
      "92/92 [==============================] - 189s 2s/step - loss: 0.1733 - acc: 0.9388 - val_loss: 0.9887 - val_acc: 0.7918\n",
      "Epoch 23/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.3682 - acc: 0.8875Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 2.1764 - acc: 0.6195Epoch 1/300\n",
      "92/92 [==============================] - 181s 2s/step - loss: 0.3699 - acc: 0.8871 - val_loss: 2.1924 - val_acc: 0.6189\n",
      "Epoch 24/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.6543 - acc: 0.8098Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 1.7623 - acc: 0.6364Epoch 1/300\n",
      "92/92 [==============================] - 176s 2s/step - loss: 0.6531 - acc: 0.8098 - val_loss: 1.7809 - val_acc: 0.6356\n",
      "Epoch 25/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.3668 - acc: 0.8764Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.6204 - acc: 0.8302Epoch 1/300\n",
      "92/92 [==============================] - 181s 2s/step - loss: 0.3654 - acc: 0.8768 - val_loss: 0.6279 - val_acc: 0.8296\n",
      "Epoch 26/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.2253 - acc: 0.9213Epoch 1/300\n",
      "92/92 [==============================] - 179s 2s/step - loss: 0.2245 - acc: 0.9216 - val_loss: 0.5460 - val_acc: 0.8500\n",
      "Epoch 27/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1741 - acc: 0.9376Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.5339 - acc: 0.8604Epoch 1/300\n",
      "92/92 [==============================] - 177s 2s/step - loss: 0.1738 - acc: 0.9377 - val_loss: 0.5432 - val_acc: 0.8593\n",
      "Epoch 28/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1542 - acc: 0.9445Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.4846 - acc: 0.8685Epoch 1/300\n",
      "92/92 [==============================] - 175s 2s/step - loss: 0.1542 - acc: 0.9444 - val_loss: 0.4934 - val_acc: 0.8678\n",
      "Epoch 29/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1391 - acc: 0.9489Epoch 1/300\n",
      "92/92 [==============================] - 181s 2s/step - loss: 0.1390 - acc: 0.9490 - val_loss: 0.5518 - val_acc: 0.8605\n",
      "Epoch 30/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1374 - acc: 0.9499Epoch 1/300\n",
      "92/92 [==============================] - 178s 2s/step - loss: 0.1373 - acc: 0.9500 - val_loss: 0.5358 - val_acc: 0.8619\n",
      "Epoch 31/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1291 - acc: 0.9521Epoch 1/300\n",
      "92/92 [==============================] - 190s 2s/step - loss: 0.1291 - acc: 0.9521 - val_loss: 0.5003 - val_acc: 0.8702\n",
      "Epoch 32/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1274 - acc: 0.9527Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.5840 - acc: 0.8569Epoch 1/300\n",
      "92/92 [==============================] - 196s 2s/step - loss: 0.1274 - acc: 0.9526 - val_loss: 0.5937 - val_acc: 0.8561\n",
      "Epoch 33/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1340 - acc: 0.9502Epoch 1/300\n",
      "92/92 [==============================] - 179s 2s/step - loss: 0.1339 - acc: 0.9502 - val_loss: 0.5380 - val_acc: 0.8635\n",
      "Epoch 34/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1289 - acc: 0.9522Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.5264 - acc: 0.8678Epoch 1/300\n",
      "92/92 [==============================] - 178s 2s/step - loss: 0.1283 - acc: 0.9524 - val_loss: 0.5370 - val_acc: 0.8671\n",
      "Epoch 35/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1172 - acc: 0.9562Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.4796 - acc: 0.8760Epoch 1/300\n",
      "92/92 [==============================] - 174s 2s/step - loss: 0.1172 - acc: 0.9562 - val_loss: 0.4900 - val_acc: 0.8752\n",
      "Epoch 36/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1122 - acc: 0.9578Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.4842 - acc: 0.8753Epoch 1/300\n",
      "92/92 [==============================] - 176s 2s/step - loss: 0.1122 - acc: 0.9578 - val_loss: 0.4966 - val_acc: 0.8744\n",
      "Epoch 37/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1078 - acc: 0.9591Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.4827 - acc: 0.8766Epoch 1/300\n",
      "92/92 [==============================] - 178s 2s/step - loss: 0.1076 - acc: 0.9592 - val_loss: 0.4954 - val_acc: 0.8756\n",
      "Epoch 38/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1066 - acc: 0.9599Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.4925 - acc: 0.8753Epoch 1/300\n",
      "92/92 [==============================] - 178s 2s/step - loss: 0.1063 - acc: 0.9600 - val_loss: 0.5031 - val_acc: 0.8745\n",
      "Epoch 39/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1035 - acc: 0.9609Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.5565 - acc: 0.8660Epoch 1/300\n",
      "92/92 [==============================] - 180s 2s/step - loss: 0.1033 - acc: 0.9609 - val_loss: 0.5714 - val_acc: 0.8651\n",
      "Epoch 40/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1138 - acc: 0.9573Epoch 1/300\n",
      "92/92 [==============================] - 177s 2s/step - loss: 0.1138 - acc: 0.9573 - val_loss: 0.5758 - val_acc: 0.8640\n",
      "Epoch 41/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1125 - acc: 0.9576Epoch 1/300\n",
      "92/92 [==============================] - 205s 2s/step - loss: 0.1128 - acc: 0.9574 - val_loss: 0.6027 - val_acc: 0.8625\n",
      "Epoch 42/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1089 - acc: 0.9588Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.5110 - acc: 0.8738Epoch 1/300\n",
      "92/92 [==============================] - 180s 2s/step - loss: 0.1086 - acc: 0.9589 - val_loss: 0.5234 - val_acc: 0.8728\n",
      "Epoch 43/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1056 - acc: 0.9601Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.4973 - acc: 0.8755Epoch 1/300\n",
      "92/92 [==============================] - 175s 2s/step - loss: 0.1056 - acc: 0.9601 - val_loss: 0.5079 - val_acc: 0.8747\n",
      "Epoch 44/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1035 - acc: 0.9608Epoch 1/300\n",
      "92/92 [==============================] - 176s 2s/step - loss: 0.1036 - acc: 0.9608 - val_loss: 0.5614 - val_acc: 0.8682\n",
      "Epoch 45/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.0994 - acc: 0.9622Epoch 1/300\n",
      "92/92 [==============================] - 243s 3s/step - loss: 0.0996 - acc: 0.9622 - val_loss: 0.5191 - val_acc: 0.8741\n",
      "Epoch 46/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1108 - acc: 0.9583Epoch 1/300\n",
      "92/92 [==============================] - 180s 2s/step - loss: 0.1111 - acc: 0.9582 - val_loss: 0.5708 - val_acc: 0.8650\n",
      "Epoch 47/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1110 - acc: 0.9580Epoch 1/300\n",
      "92/92 [==============================] - 183s 2s/step - loss: 0.1107 - acc: 0.9581 - val_loss: 0.5710 - val_acc: 0.8666\n",
      "Epoch 48/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1733 - acc: 0.9423Epoch 1/300\n",
      "92/92 [==============================] - 178s 2s/step - loss: 0.1735 - acc: 0.9422 - val_loss: 2.3177 - val_acc: 0.5986\n",
      "Epoch 49/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.8707 - acc: 0.7738Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 9.7184 - acc: 0.2041Epoch 1/300\n",
      "92/92 [==============================] - 176s 2s/step - loss: 0.8693 - acc: 0.7738 - val_loss: 9.7621 - val_acc: 0.2033\n",
      "Epoch 50/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.5650 - acc: 0.8214Epoch 1/300\n",
      "92/92 [==============================] - 202s 2s/step - loss: 0.5651 - acc: 0.8216 - val_loss: 0.8917 - val_acc: 0.7771\n",
      "Epoch 51/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.3394 - acc: 0.8851Epoch 1/300\n",
      "92/92 [==============================] - 173s 2s/step - loss: 0.3395 - acc: 0.8851 - val_loss: 0.6810 - val_acc: 0.8268\n",
      "Epoch 52/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.2221 - acc: 0.9221Epoch 1/300\n",
      "92/92 [==============================] - 181s 2s/step - loss: 0.2222 - acc: 0.9220 - val_loss: 0.6108 - val_acc: 0.8430\n",
      "Epoch 53/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1903 - acc: 0.9328Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.5794 - acc: 0.8454Epoch 1/300\n",
      "92/92 [==============================] - 174s 2s/step - loss: 0.1901 - acc: 0.9329 - val_loss: 0.5890 - val_acc: 0.8446\n",
      "Epoch 54/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1496 - acc: 0.9466Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.5723 - acc: 0.8535Epoch 1/300\n",
      "92/92 [==============================] - 178s 2s/step - loss: 0.1495 - acc: 0.9466 - val_loss: 0.5840 - val_acc: 0.8528\n",
      "Epoch 55/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1350 - acc: 0.9506Epoch 1/300\n",
      "92/92 [==============================] - 187s 2s/step - loss: 0.1346 - acc: 0.9508 - val_loss: 0.5620 - val_acc: 0.8567\n",
      "Epoch 56/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1228 - acc: 0.9548Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 1s - loss: 0.5174 - acc: 0.8664Epoch 1/300\n",
      "92/92 [==============================] - 180s 2s/step - loss: 0.1227 - acc: 0.9548 - val_loss: 0.5283 - val_acc: 0.8656\n",
      "Epoch 57/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1161 - acc: 0.9572Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 0.5368 - acc: 0.8640Epoch 1/300\n",
      "92/92 [==============================] - 232s 3s/step - loss: 0.1164 - acc: 0.9571 - val_loss: 0.5483 - val_acc: 0.8632\n",
      "Epoch 58/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1130 - acc: 0.9581Epoch 1/300\n",
      "92/92 [==============================] - 181s 2s/step - loss: 0.1132 - acc: 0.9580 - val_loss: 0.5134 - val_acc: 0.8702\n",
      "Epoch 59/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1118 - acc: 0.9582Epoch 1/300\n",
      "92/92 [==============================] - 184s 2s/step - loss: 0.1117 - acc: 0.9583 - val_loss: 0.5462 - val_acc: 0.8661\n",
      "Epoch 60/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.1082 - acc: 0.9594Epoch 1/300\n",
      "57/92 [=================>............] - ETA: 22s - loss: 0.5150 - acc: 0.8697"
     ]
    }
   ],
   "source": [
    "#hist = model.fit_generator(data_gen, validation_data=(valid_x, valid_y), epochs=par.n_epochs, steps_per_epoch=par.n_batch, callbacks=[cp_cb])\n",
    "hist = model.fit_generator(train_data_gen,\n",
    "                           epochs=n_epochs,\n",
    "                           steps_per_epoch=len(train_data_gen),\n",
    "                           validation_data=valid_data_gen,\n",
    "                           validation_steps=len(valid_data_gen),\n",
    "                           shuffle = True,\n",
    "                           workers=8,\n",
    "                           use_multiprocessing=True,\n",
    "                           callbacks=[cp_cb])\n",
    "#hist = model.fit_generator(data_gen, epochs=par.n_epochs, steps_per_epoch=par.n_batch, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(hist.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(hist.history[\"acc\"], label=\"acc\")\n",
    "plt.plot(hist.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(out_dir,'losscurve.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(out_dir,'final_epoch.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
