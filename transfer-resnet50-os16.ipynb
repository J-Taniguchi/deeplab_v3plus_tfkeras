{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabv3plus_dir=\"./src\"\n",
    "sys.path.append(deeplabv3plus_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(visible_device_list=\"2\", allow_growth=True)\n",
    "config = tf.compat.v1.ConfigProto(gpu_options = gpu_options)\n",
    "tf.compat.v1.enable_eager_execution(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import deeplab_v3plus_transfer_resnet_os16\n",
    "#from image_utils import make_x_from_image_paths,make_y_from_image_paths,convert_y_to_image_array\n",
    "from data_gen import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from './src/model.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(sys.modules['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"resnet50_transfer_os16\"\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories = 21\n",
    "image_size = (512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_img_dir = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/SegmentationClass\"\n",
    "img_dir = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/JPEGImages\"\n",
    "train_set_path = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt\"\n",
    "valid_set_path = \"../pascal_voc_2012_datasets/VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt\"\n",
    "\n",
    "with open(train_set_path) as f:\n",
    "    train_img_names = f.read().split(\"\\n\")[:-1]\n",
    "with open(valid_set_path) as f:\n",
    "    valid_img_names = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "img_paths = [os.path.join(img_dir,train_img_names[i]) + \".jpg\" for i in range(len(train_img_names))]\n",
    "seg_img_paths = [os.path.join(seg_img_dir,train_img_names[i]) + \".png\" for i in range(len(train_img_names))]\n",
    "\n",
    "valid_x_paths = [os.path.join(img_dir,valid_img_names[i]) + \".jpg\" for i in range(len(valid_img_names))]\n",
    "valid_y_paths = [os.path.join(seg_img_dir,valid_img_names[i]) + \".png\" for i in range(len(valid_img_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "n_epochs=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.applications.ResNet50(input_shape=(512,512,3), weights=\"imagenet\", include_top=False)\n",
    "preprocess = keras.applications.resnet50.preprocess_input\n",
    "layer_name_to_decoder = \"conv2_block3_out\"\n",
    "encoder_end_layer_name = \"conv4_block6_out\"\n",
    "model = deeplab_v3plus_transfer_resnet_os16(n_categories, encoder, layer_name_to_decoder, encoder_end_layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50_deeplab-v3plus\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 518, 518, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 256, 256, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 256, 256, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 256, 256, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 258, 258, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 128, 128, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 128, 128, 64) 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 128, 128, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 128, 128, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 128, 128, 256 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 128, 128, 256 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 128, 128, 256 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 128, 128, 64) 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 128, 128, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 128, 128, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 128, 128, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 128, 128, 256 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 128, 128, 64) 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 128, 128, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 128, 128, 64) 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 128, 128, 256 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 128, 128, 256 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 64, 64, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 64, 64, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 64, 64, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 64, 64, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 64, 64, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 64, 64, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 64, 64, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 64, 64, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 64, 64, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 64, 64, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 64, 64, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 64, 64, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 64, 64, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 64, 64, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 64, 64, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 64, 64, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 64, 64, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 64, 64, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 32, 32, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 32, 32, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 32, 32, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 32, 32, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 32, 32, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 32, 32, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 32, 32, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 32, 32, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 32, 32, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 32, 32, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 32, 32, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 32, 32, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 32, 32, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 32, 32, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 32, 32, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 32, 32, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 32, 32, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 32, 32, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 32, 32, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 32, 32, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 32, 32, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 32, 32, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 32, 32, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 32, 32, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 32, 32, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 32, 32, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "aspp2_sc1 (DepthwiseConv2D)     (None, 32, 32, 1024) 10240       conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "aspp3_sc1 (DepthwiseConv2D)     (None, 32, 32, 1024) 10240       conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "aspp4_sc1 (DepthwiseConv2D)     (None, 32, 32, 1024) 10240       conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "aspp2_sc-bn1 (BatchNormalizatio (None, 32, 32, 1024) 4096        aspp2_sc1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp3_sc-bn1 (BatchNormalizatio (None, 32, 32, 1024) 4096        aspp3_sc1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp4_sc-bn1 (BatchNormalizatio (None, 32, 32, 1024) 4096        aspp4_sc1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(None, 1, 1, 1024)] 0           conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "aspp2_sc-act1 (Activation)      (None, 32, 32, 1024) 0           aspp2_sc-bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aspp3_sc-act1 (Activation)      (None, 32, 32, 1024) 0           aspp3_sc-bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aspp4_sc-act1 (Activation)      (None, 32, 32, 1024) 0           aspp4_sc-bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aspp5_cv1 (Conv2D)              (None, 1, 1, 256)    262400      tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "aspp1_cv1 (Conv2D)              (None, 32, 32, 256)  262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "aspp2_cv1 (Conv2D)              (None, 32, 32, 256)  262400      aspp2_sc-act1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aspp3_cv1 (Conv2D)              (None, 32, 32, 256)  262400      aspp3_sc-act1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aspp4_cv1 (Conv2D)              (None, 32, 32, 256)  262400      aspp4_sc-act1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aspp5_bn1 (BatchNormalization)  (None, 1, 1, 256)    1024        aspp5_cv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp1_bn1 (BatchNormalization)  (None, 32, 32, 256)  1024        aspp1_cv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp2_cv-bn1 (BatchNormalizatio (None, 32, 32, 256)  1024        aspp2_cv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp3_cv-bn1 (BatchNormalizatio (None, 32, 32, 256)  1024        aspp3_cv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp4_cv-bn1 (BatchNormalizatio (None, 32, 32, 256)  1024        aspp4_cv1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp5_act1 (Activation)         (None, 1, 1, 256)    0           aspp5_bn1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp1_act1 (Activation)         (None, 32, 32, 256)  0           aspp1_bn1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aspp2_cv-act1 (Activation)      (None, 32, 32, 256)  0           aspp2_cv-bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aspp3_cv-act1 (Activation)      (None, 32, 32, 256)  0           aspp3_cv-bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aspp4_cv-act1 (Activation)      (None, 32, 32, 256)  0           aspp4_cv-bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aspp5_upsampling (UpSampling2D) (None, 32, 32, 256)  0           aspp5_act1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ASPP (Concatenate)              (None, 32, 32, 1280) 0           aspp1_act1[0][0]                 \n",
      "                                                                 aspp2_cv-act1[0][0]              \n",
      "                                                                 aspp3_cv-act1[0][0]              \n",
      "                                                                 aspp4_cv-act1[0][0]              \n",
      "                                                                 aspp5_upsampling[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "ASPP_cv1 (Conv2D)               (None, 32, 32, 256)  327936      ASPP[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dec1_cv1 (Conv2D)               (None, 128, 128, 256 65792       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "ASPP_bn1 (BatchNormalization)   (None, 32, 32, 256)  1024        ASPP_cv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec1_bn1 (BatchNormalization)   (None, 128, 128, 256 1024        dec1_cv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ASPP_act1 (Activation)          (None, 32, 32, 256)  0           ASPP_bn1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec1_act1 (Activation)          (None, 128, 128, 256 0           dec1_bn1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ASPP_upsample_4 (UpSampling2D)  (None, 128, 128, 256 0           ASPP_act1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_concat (Concatenate)        (None, 128, 128, 512 0           dec1_act1[0][0]                  \n",
      "                                                                 ASPP_upsample_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dec1_sc2 (DepthwiseConv2D)      (None, 128, 128, 512 5120        dec_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec1_sc-bn2 (BatchNormalization (None, 128, 128, 512 2048        dec1_sc2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec1_sc-act2 (Activation)       (None, 128, 128, 512 0           dec1_sc-bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec1_cv2 (Conv2D)               (None, 128, 128, 256 131328      dec1_sc-act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dec1_cv-bn2 (BatchNormalization (None, 128, 128, 256 1024        dec1_cv2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec1_cv-act2 (Activation)       (None, 128, 128, 256 0           dec1_cv-bn2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_upsample_2 (UpSampling2D)   (None, 256, 256, 256 0           dec1_cv-act2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dec2_sc1 (DepthwiseConv2D)      (None, 256, 256, 256 2560        dec_upsample_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dec2_sc-bn1 (BatchNormalization (None, 256, 256, 256 1024        dec2_sc1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec2_sc-act1 (Activation)       (None, 256, 256, 256 0           dec2_sc-bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec2_cv1 (Conv2D)               (None, 256, 256, 21) 5397        dec2_sc-act1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dec2_cv-bn1 (BatchNormalization (None, 256, 256, 21) 84          dec2_cv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 256, 256, 21) 0           dec2_cv-bn1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dec_upsample_3 (UpSampling2D)   (None, 512, 512, 21) 0           softmax[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,493,673\n",
      "Trainable params: 1,892,671\n",
      "Non-trainable params: 8,601,002\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = DataGenerator(n_categories, image_size, batch_size, img_paths    , seg_img_paths, preprocess=preprocess, augmentation=True )\n",
    "valid_data_gen = DataGenerator(n_categories, image_size, batch_size, valid_x_paths, valid_y_paths, preprocess=preprocess, augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.categorical_crossentropy\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "iou =  keras.metrics.MeanIoU(num_classes=21)\n",
    "model.compile(optimizer=opt, loss=loss_function, metrics=[\"accuracy\", iou])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(out_dir,'{epoch:06d}.h5')\n",
    "cp_cb = keras.callbacks.ModelCheckpoint(filepath, \n",
    "                                        monitor='val_loss', \n",
    "                                        verbose=0, \n",
    "                                        save_best_only=True, \n",
    "                                        save_weights_only=False, \n",
    "                                        mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1129 10:26:27.069119 140736002870480 deprecation.py:323] From /home/taniguchi-j/anaconda3/envs/ppc/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/92 [============================>.] - ETA: 2s - loss: 2.4601 - acc: 0.5793 - mean_io_u: 0.4762Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 2.5403 - acc: 0.7486 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 303s 3s/step - loss: 2.4584 - acc: 0.5804 - mean_io_u: 0.4762 - val_loss: 2.5418 - val_acc: 0.7476 - val_mean_io_u: 0.4762\n",
      "Epoch 2/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 2.1221 - acc: 0.6915 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 285s 3s/step - loss: 2.1213 - acc: 0.6919 - mean_io_u: 0.4762 - val_loss: 2.2457 - val_acc: 0.7476 - val_mean_io_u: 0.4762\n",
      "Epoch 3/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 1.9482 - acc: 0.7221 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 278s 3s/step - loss: 1.9482 - acc: 0.7218 - mean_io_u: 0.4762 - val_loss: 1.9772 - val_acc: 0.7487 - val_mean_io_u: 0.4762\n",
      "Epoch 4/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 1.7806 - acc: 0.7491 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 289s 3s/step - loss: 1.7805 - acc: 0.7488 - mean_io_u: 0.4762 - val_loss: 1.7287 - val_acc: 0.7725 - val_mean_io_u: 0.4762\n",
      "Epoch 5/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 1.6334 - acc: 0.7650 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 278s 3s/step - loss: 1.6341 - acc: 0.7643 - mean_io_u: 0.4762 - val_loss: 1.4438 - val_acc: 0.8288 - val_mean_io_u: 0.4762\n",
      "Epoch 6/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 1.5184 - acc: 0.7831 - mean_io_u: 0.4762Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 1.2595 - acc: 0.8404 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 283s 3s/step - loss: 1.5153 - acc: 0.7834 - mean_io_u: 0.4762 - val_loss: 1.2626 - val_acc: 0.8398 - val_mean_io_u: 0.4762\n",
      "Epoch 7/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 1.3977 - acc: 0.7947 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 287s 3s/step - loss: 1.3988 - acc: 0.7944 - mean_io_u: 0.4762 - val_loss: 1.1835 - val_acc: 0.8438 - val_mean_io_u: 0.4762\n",
      "Epoch 8/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 1.2933 - acc: 0.8070 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 288s 3s/step - loss: 1.2926 - acc: 0.8072 - mean_io_u: 0.4762 - val_loss: 1.0532 - val_acc: 0.8527 - val_mean_io_u: 0.4762\n",
      "Epoch 9/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 1.2094 - acc: 0.8153 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 291s 3s/step - loss: 1.2088 - acc: 0.8153 - mean_io_u: 0.4762 - val_loss: 1.0443 - val_acc: 0.8437 - val_mean_io_u: 0.4762\n",
      "Epoch 10/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 1.1075 - acc: 0.8292 - mean_io_u: 0.4762Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 1.0380 - acc: 0.8371 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 288s 3s/step - loss: 1.1072 - acc: 0.8295 - mean_io_u: 0.4762 - val_loss: 1.0412 - val_acc: 0.8365 - val_mean_io_u: 0.4762\n",
      "Epoch 11/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 1.0386 - acc: 0.8347 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 286s 3s/step - loss: 1.0391 - acc: 0.8347 - mean_io_u: 0.4762 - val_loss: 0.9193 - val_acc: 0.8517 - val_mean_io_u: 0.4762\n",
      "Epoch 12/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.9687 - acc: 0.8411 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 286s 3s/step - loss: 0.9676 - acc: 0.8414 - mean_io_u: 0.4762 - val_loss: 0.9527 - val_acc: 0.8449 - val_mean_io_u: 0.4762\n",
      "Epoch 13/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.8974 - acc: 0.8507 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 289s 3s/step - loss: 0.8976 - acc: 0.8509 - mean_io_u: 0.4762 - val_loss: 0.8197 - val_acc: 0.8526 - val_mean_io_u: 0.4762\n",
      "Epoch 14/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.8482 - acc: 0.8556 - mean_io_u: 0.4762Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 0.8847 - acc: 0.8365 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 288s 3s/step - loss: 0.8486 - acc: 0.8554 - mean_io_u: 0.4762 - val_loss: 0.8915 - val_acc: 0.8358 - val_mean_io_u: 0.4762\n",
      "Epoch 15/300\n",
      "91/92 [============================>.] - ETA: 2s - loss: 0.7996 - acc: 0.8602 - mean_io_u: 0.4762Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 0.8352 - acc: 0.8438 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 362s 4s/step - loss: 0.7988 - acc: 0.8602 - mean_io_u: 0.4762 - val_loss: 0.8381 - val_acc: 0.8435 - val_mean_io_u: 0.4762\n",
      "Epoch 16/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.7647 - acc: 0.8616 - mean_io_u: 0.4762Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 0.7825 - acc: 0.8486 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 290s 3s/step - loss: 0.7638 - acc: 0.8618 - mean_io_u: 0.4762 - val_loss: 0.7876 - val_acc: 0.8481 - val_mean_io_u: 0.4762\n",
      "Epoch 17/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.7180 - acc: 0.8670 - mean_io_u: 0.4762Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 0.7626 - acc: 0.8477 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 283s 3s/step - loss: 0.7177 - acc: 0.8672 - mean_io_u: 0.4762 - val_loss: 0.7705 - val_acc: 0.8467 - val_mean_io_u: 0.4762\n",
      "Epoch 18/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.6798 - acc: 0.8710 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 298s 3s/step - loss: 0.6790 - acc: 0.8710 - mean_io_u: 0.4762 - val_loss: 0.6740 - val_acc: 0.8609 - val_mean_io_u: 0.4762\n",
      "Epoch 19/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.6440 - acc: 0.8748 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 284s 3s/step - loss: 0.6457 - acc: 0.8741 - mean_io_u: 0.4762 - val_loss: 0.7031 - val_acc: 0.8557 - val_mean_io_u: 0.4762\n",
      "Epoch 20/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.6120 - acc: 0.8795 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 279s 3s/step - loss: 0.6140 - acc: 0.8786 - mean_io_u: 0.4762 - val_loss: 0.6680 - val_acc: 0.8581 - val_mean_io_u: 0.4762\n",
      "Epoch 21/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.5821 - acc: 0.8839 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 287s 3s/step - loss: 0.5817 - acc: 0.8839 - mean_io_u: 0.4762 - val_loss: 0.6354 - val_acc: 0.8633 - val_mean_io_u: 0.4762\n",
      "Epoch 22/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.5607 - acc: 0.8843 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 288s 3s/step - loss: 0.5599 - acc: 0.8845 - mean_io_u: 0.4762 - val_loss: 0.6384 - val_acc: 0.8600 - val_mean_io_u: 0.4762\n",
      "Epoch 23/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.5375 - acc: 0.8876 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 279s 3s/step - loss: 0.5377 - acc: 0.8875 - mean_io_u: 0.4762 - val_loss: 0.6016 - val_acc: 0.8648 - val_mean_io_u: 0.4762\n",
      "Epoch 24/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.5085 - acc: 0.8926 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 283s 3s/step - loss: 0.5093 - acc: 0.8922 - mean_io_u: 0.4762 - val_loss: 0.6469 - val_acc: 0.8516 - val_mean_io_u: 0.4762\n",
      "Epoch 25/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.4878 - acc: 0.8950 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 280s 3s/step - loss: 0.4873 - acc: 0.8952 - mean_io_u: 0.4762 - val_loss: 0.6450 - val_acc: 0.8518 - val_mean_io_u: 0.4762\n",
      "Epoch 26/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.4827 - acc: 0.8915 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 279s 3s/step - loss: 0.4822 - acc: 0.8919 - mean_io_u: 0.4762 - val_loss: 0.5998 - val_acc: 0.8623 - val_mean_io_u: 0.4762\n",
      "Epoch 27/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.4687 - acc: 0.8945 - mean_io_u: 0.4762Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 0.5861 - acc: 0.8625 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 282s 3s/step - loss: 0.4686 - acc: 0.8944 - mean_io_u: 0.4762 - val_loss: 0.5936 - val_acc: 0.8616 - val_mean_io_u: 0.4762\n",
      "Epoch 28/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.4449 - acc: 0.8978 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 278s 3s/step - loss: 0.4450 - acc: 0.8979 - mean_io_u: 0.4762 - val_loss: 0.6118 - val_acc: 0.8605 - val_mean_io_u: 0.4762\n",
      "Epoch 29/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.4253 - acc: 0.9015 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 278s 3s/step - loss: 0.4260 - acc: 0.9013 - mean_io_u: 0.4762 - val_loss: 0.5791 - val_acc: 0.8619 - val_mean_io_u: 0.4762\n",
      "Epoch 30/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.4292 - acc: 0.8974 - mean_io_u: 0.4762Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 0.6184 - acc: 0.8511 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 285s 3s/step - loss: 0.4287 - acc: 0.8976 - mean_io_u: 0.4762 - val_loss: 0.6233 - val_acc: 0.8504 - val_mean_io_u: 0.4762\n",
      "Epoch 31/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.4107 - acc: 0.9021 - mean_io_u: 0.4762Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 0.6063 - acc: 0.8569 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 290s 3s/step - loss: 0.4101 - acc: 0.9024 - mean_io_u: 0.4762 - val_loss: 0.6118 - val_acc: 0.8565 - val_mean_io_u: 0.4762\n",
      "Epoch 32/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.4020 - acc: 0.9022 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 307s 3s/step - loss: 0.4017 - acc: 0.9023 - mean_io_u: 0.4762 - val_loss: 0.6623 - val_acc: 0.8490 - val_mean_io_u: 0.4762\n",
      "Epoch 33/300\n",
      "91/92 [============================>.] - ETA: 2s - loss: 0.3753 - acc: 0.9085 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 338s 4s/step - loss: 0.3753 - acc: 0.9085 - mean_io_u: 0.4762 - val_loss: 0.5359 - val_acc: 0.8656 - val_mean_io_u: 0.4762\n",
      "Epoch 34/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.3706 - acc: 0.9082 - mean_io_u: 0.4762Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 0.5329 - acc: 0.8621 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 285s 3s/step - loss: 0.3710 - acc: 0.9079 - mean_io_u: 0.4762 - val_loss: 0.5379 - val_acc: 0.8616 - val_mean_io_u: 0.4762\n",
      "Epoch 35/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.3634 - acc: 0.9092 - mean_io_u: 0.4762Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 0.5689 - acc: 0.8602 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 283s 3s/step - loss: 0.3629 - acc: 0.9093 - mean_io_u: 0.4762 - val_loss: 0.5752 - val_acc: 0.8597 - val_mean_io_u: 0.4762\n",
      "Epoch 36/300\n",
      "91/92 [============================>.] - ETA: 2s - loss: 0.3630 - acc: 0.9072 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 311s 3s/step - loss: 0.3632 - acc: 0.9072 - mean_io_u: 0.4762 - val_loss: 0.5491 - val_acc: 0.8623 - val_mean_io_u: 0.4762\n",
      "Epoch 37/300\n",
      "91/92 [============================>.] - ETA: 2s - loss: 0.3378 - acc: 0.9129 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 315s 3s/step - loss: 0.3374 - acc: 0.9130 - mean_io_u: 0.4762 - val_loss: 0.5828 - val_acc: 0.8562 - val_mean_io_u: 0.4762\n",
      "Epoch 38/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.3348 - acc: 0.9136 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 280s 3s/step - loss: 0.3357 - acc: 0.9134 - mean_io_u: 0.4762 - val_loss: 0.5516 - val_acc: 0.8643 - val_mean_io_u: 0.4762\n",
      "Epoch 39/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.3316 - acc: 0.9128 - mean_io_u: 0.4762Epoch 1/300\n",
      "90/92 [============================>.] - ETA: 2s - loss: 0.5553 - acc: 0.8636 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 272s 3s/step - loss: 0.3308 - acc: 0.9131 - mean_io_u: 0.4762 - val_loss: 0.5603 - val_acc: 0.8631 - val_mean_io_u: 0.4762\n",
      "Epoch 40/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.3169 - acc: 0.9161 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 272s 3s/step - loss: 0.3164 - acc: 0.9164 - mean_io_u: 0.4762 - val_loss: 0.5687 - val_acc: 0.8557 - val_mean_io_u: 0.4762\n",
      "Epoch 41/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.3138 - acc: 0.9159 - mean_io_u: 0.4762Epoch 1/300\n",
      "92/92 [==============================] - 349s 4s/step - loss: 0.3138 - acc: 0.9159 - mean_io_u: 0.4762 - val_loss: 0.5545 - val_acc: 0.8639 - val_mean_io_u: 0.4762\n",
      "Epoch 42/300\n",
      "91/92 [============================>.] - ETA: 1s - loss: 0.3020 - acc: 0.9186 - mean_io_u: 0.4762Epoch 1/300\n",
      "54/92 [================>.............] - ETA: 58s - loss: 0.5480 - acc: 0.8587 - mean_io_u: 0.4762 "
     ]
    }
   ],
   "source": [
    "#hist = model.fit_generator(data_gen, validation_data=(valid_x, valid_y), epochs=par.n_epochs, steps_per_epoch=par.n_batch, callbacks=[cp_cb])\n",
    "hist = model.fit_generator(train_data_gen,\n",
    "                           epochs=n_epochs,\n",
    "                           steps_per_epoch=len(train_data_gen),\n",
    "                           validation_data=valid_data_gen,\n",
    "                           validation_steps=len(valid_data_gen),\n",
    "                           shuffle = True,\n",
    "                           workers=8,\n",
    "                           use_multiprocessing=True,\n",
    "                           callbacks=[cp_cb])\n",
    "#hist = model.fit_generator(data_gen, epochs=par.n_epochs, steps_per_epoch=par.n_batch, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(hist.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(hist.history[\"acc\"], label=\"acc\")\n",
    "plt.plot(hist.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(out_dir,'losscurve.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(out_dir,'final_epoch.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for key in sorted(hist.history.keys()):\n",
    "    np.savetxt(os.path.join(out_dir,key+'.txt'),np.array(hist.history[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
